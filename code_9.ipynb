{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_shape: [32, 32, 3]\n",
      "image_data: 275580\n",
      "labels: 275580\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "shared_dir = '/Users/prateek/Desktop/ML/Major/augmented/'\n",
    "infected_dir = shared_dir + 'True_parasitized/'\n",
    "uninfected_dir = shared_dir + 'True_uninfected/'\n",
    "input_shape = [32, 32]\n",
    "batch = 32\n",
    "\n",
    "parasitized_data = os.listdir(infected_dir)\n",
    "uninfected_data = os.listdir(uninfected_dir)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for img in parasitized_data:\n",
    "    try:\n",
    "        img_read = plt.imread(infected_dir + img)\n",
    "        img_resize = cv2.resize(img_read, input_shape)\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(1)\n",
    "    except :\n",
    "        None\n",
    "        \n",
    "for img in uninfected_data:\n",
    "    try:\n",
    "        img_read = plt.imread(uninfected_dir + img)\n",
    "        img_resize = cv2.resize(img_read, input_shape)\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(0)\n",
    "    except:\n",
    "        None\n",
    "\n",
    "shared_dir = '/Users/prateek/Desktop/ML/Major/augmented/'\n",
    "infected_dir = shared_dir + 'False_uninfected/'\n",
    "uninfected_dir = shared_dir + 'False_parasitized/'\n",
    "input_shape = [32, 32]\n",
    "batch = 32\n",
    "\n",
    "parasitized_data = os.listdir(infected_dir)\n",
    "uninfected_data = os.listdir(uninfected_dir)\n",
    "\n",
    "for img in parasitized_data:\n",
    "    try:\n",
    "        img_read = plt.imread(infected_dir + img)\n",
    "        img_resize = cv2.resize(img_read, input_shape)\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(1)\n",
    "    except :\n",
    "        None\n",
    "        \n",
    "for img in uninfected_data:\n",
    "    try:\n",
    "        img_read = plt.imread(uninfected_dir + img)\n",
    "        img_resize = cv2.resize(img_read, input_shape)\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(0)\n",
    "    except:\n",
    "        None\n",
    "\n",
    "input_shape.append(3)\n",
    "image_data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"image_shape:\", input_shape)\n",
    "print(\"image_data:\",len(image_data))\n",
    "print(\"labels:\",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 220464\n",
      "X_test: 55116\n",
      "y_train: 220464\n",
      "y_test: 55116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size = 0.2,random_state = 0)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes = 2)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes = 2)\n",
    "\n",
    "print(\"X_train:\",len(X_train))\n",
    "print(\"X_test:\",len(X_test))\n",
    "print(\"y_train:\",len(y_train))\n",
    "print(\"y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D, GlobalMaxPooling2D,GlobalAveragePooling2D,Activation,Dropout\n",
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.python.keras import Sequential,backend,optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 32, 3]\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 12:29:54.135072: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-24 12:29:54.135365: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 4)         112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 4)         0         \n",
      "_________________________________________________________________\n",
      "module_wrapper (ModuleWrappe (None, 15, 15, 4)         16        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 8)         520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_1 (ModuleWrap (None, 6, 6, 8)           32        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_2 (ModuleWrap (None, 2, 2, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 64)          1088      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "module_wrapper_3 (ModuleWrap (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "module_wrapper_4 (ModuleWrap (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 39,610\n",
      "Trainable params: 38,402\n",
      "Non-trainable params: 1,208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dropout_rate = 0.2\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    input_shape = input_shape.reverse\n",
    "print(input_shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=(4, 4),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# model.add( Conv2D(filters=64, kernel_size=1, strides=1))\n",
    "# model.add( Dropout(dropout_rate))\n",
    "# model.add( BatchNormalization())\n",
    "model.add( Activation('relu'))\n",
    "model.add( Conv2D(filters=64, kernel_size=1, strides=1))\n",
    "model.add( Dropout(dropout_rate))\n",
    "model.add( BatchNormalization(axis=-1))\n",
    "model.add( GlobalMaxPooling2D())\n",
    "\n",
    "model.add( Flatten())\n",
    "model.add( Dense(512, activation = 'relu'))\n",
    "model.add( BatchNormalization(axis = -1))\n",
    "model.add( Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateek/venv/ml/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "optimizer = SGD(lr=1)\n",
    "epochs = 300\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    decay_rate = 0.1\n",
    "    decay_step = 20\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * pow(decay_rate, np.floor(epoch / decay_step))\n",
    "    return lr\n",
    "\n",
    "callbacks = [LearningRateScheduler(lr_scheduler, verbose=42)]\n",
    "\n",
    "accuracy = [tf.keras.metrics.Accuracy(), tf.keras.metrics.BinaryAccuracy()]\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 12:29:58.250842: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-24 12:29:59.847120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6201/6201 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.0144 - binary_accuracy: 0.7879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 12:34:38.955259: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6201/6201 [==============================] - 301s 48ms/step - loss: 0.2938 - accuracy: 0.0144 - binary_accuracy: 0.7879 - val_loss: 0.2779 - val_accuracy: 0.0223 - val_binary_accuracy: 0.8783\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 318s 51ms/step - loss: 0.1927 - accuracy: 0.0221 - binary_accuracy: 0.8950 - val_loss: 0.2366 - val_accuracy: 0.0231 - val_binary_accuracy: 0.9064\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 322s 52ms/step - loss: 0.1801 - accuracy: 0.0257 - binary_accuracy: 0.9126 - val_loss: 0.2294 - val_accuracy: 0.0286 - val_binary_accuracy: 0.9177\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 321s 52ms/step - loss: 0.1742 - accuracy: 0.0316 - binary_accuracy: 0.9211 - val_loss: 0.2779 - val_accuracy: 0.0342 - val_binary_accuracy: 0.9238\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 321s 52ms/step - loss: 0.1705 - accuracy: 0.0356 - binary_accuracy: 0.9257 - val_loss: 0.2293 - val_accuracy: 0.0374 - val_binary_accuracy: 0.9275\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 331s 53ms/step - loss: 0.1709 - accuracy: 0.0397 - binary_accuracy: 0.9288 - val_loss: 0.3147 - val_accuracy: 0.0422 - val_binary_accuracy: 0.9299\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 323s 52ms/step - loss: 0.1653 - accuracy: 0.0440 - binary_accuracy: 0.9309 - val_loss: 0.2871 - val_accuracy: 0.0451 - val_binary_accuracy: 0.9318\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 336s 54ms/step - loss: 0.1623 - accuracy: 0.0460 - binary_accuracy: 0.9326 - val_loss: 0.3033 - val_accuracy: 0.0469 - val_binary_accuracy: 0.9333\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 327s 53ms/step - loss: 0.1593 - accuracy: 0.0479 - binary_accuracy: 0.9340 - val_loss: 0.2629 - val_accuracy: 0.0486 - val_binary_accuracy: 0.9346\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 338s 54ms/step - loss: 0.1595 - accuracy: 0.0491 - binary_accuracy: 0.9352 - val_loss: 0.3188 - val_accuracy: 0.0499 - val_binary_accuracy: 0.9357\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 318s 51ms/step - loss: 0.1571 - accuracy: 0.0506 - binary_accuracy: 0.9362 - val_loss: 0.3567 - val_accuracy: 0.0509 - val_binary_accuracy: 0.9367\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 330s 53ms/step - loss: 0.1565 - accuracy: 0.0514 - binary_accuracy: 0.9371 - val_loss: 0.2764 - val_accuracy: 0.0519 - val_binary_accuracy: 0.9375\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 330s 53ms/step - loss: 0.1524 - accuracy: 0.0525 - binary_accuracy: 0.9379 - val_loss: 0.2531 - val_accuracy: 0.0530 - val_binary_accuracy: 0.9384\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 323s 52ms/step - loss: 0.1525 - accuracy: 0.0534 - binary_accuracy: 0.9387 - val_loss: 0.2478 - val_accuracy: 0.0539 - val_binary_accuracy: 0.9391\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 331s 53ms/step - loss: 0.1526 - accuracy: 0.0542 - binary_accuracy: 0.9394 - val_loss: 0.2071 - val_accuracy: 0.0544 - val_binary_accuracy: 0.9397\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 326s 53ms/step - loss: 0.1508 - accuracy: 0.0547 - binary_accuracy: 0.9401 - val_loss: 0.2253 - val_accuracy: 0.0550 - val_binary_accuracy: 0.9403\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 313s 51ms/step - loss: 0.1505 - accuracy: 0.0554 - binary_accuracy: 0.9407 - val_loss: 0.2716 - val_accuracy: 0.0556 - val_binary_accuracy: 0.9409\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 324s 52ms/step - loss: 0.1503 - accuracy: 0.0558 - binary_accuracy: 0.9412 - val_loss: 0.2051 - val_accuracy: 0.0559 - val_binary_accuracy: 0.9414\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 2578s 416ms/step - loss: 0.1491 - accuracy: 0.0561 - binary_accuracy: 0.9417 - val_loss: 0.2598 - val_accuracy: 0.0562 - val_binary_accuracy: 0.9418\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "6201/6201 [==============================] - 352s 57ms/step - loss: 0.1501 - accuracy: 0.0562 - binary_accuracy: 0.9420 - val_loss: 0.3837 - val_accuracy: 0.0569 - val_binary_accuracy: 0.9422\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 335s 54ms/step - loss: 0.1426 - accuracy: 0.0577 - binary_accuracy: 0.9423 - val_loss: 0.2723 - val_accuracy: 0.0582 - val_binary_accuracy: 0.9426\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 314s 51ms/step - loss: 0.1406 - accuracy: 0.0588 - binary_accuracy: 0.9428 - val_loss: 0.2731 - val_accuracy: 0.0594 - val_binary_accuracy: 0.9430\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 216s 35ms/step - loss: 0.1402 - accuracy: 0.0599 - binary_accuracy: 0.9433 - val_loss: 0.2753 - val_accuracy: 0.0605 - val_binary_accuracy: 0.9435\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 182s 29ms/step - loss: 0.1403 - accuracy: 0.0610 - binary_accuracy: 0.9437 - val_loss: 0.2828 - val_accuracy: 0.0615 - val_binary_accuracy: 0.9438\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 181s 29ms/step - loss: 0.1397 - accuracy: 0.0621 - binary_accuracy: 0.9441 - val_loss: 0.2492 - val_accuracy: 0.0624 - val_binary_accuracy: 0.9442\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 199s 32ms/step - loss: 0.1399 - accuracy: 0.0627 - binary_accuracy: 0.9443 - val_loss: 0.2608 - val_accuracy: 0.0631 - val_binary_accuracy: 0.9445\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 194s 31ms/step - loss: 0.1388 - accuracy: 0.0635 - binary_accuracy: 0.9447 - val_loss: 0.2840 - val_accuracy: 0.0639 - val_binary_accuracy: 0.9449\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 185s 30ms/step - loss: 0.1389 - accuracy: 0.0644 - binary_accuracy: 0.9451 - val_loss: 0.2640 - val_accuracy: 0.0649 - val_binary_accuracy: 0.9451\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 211s 34ms/step - loss: 0.1388 - accuracy: 0.0653 - binary_accuracy: 0.9453 - val_loss: 0.2550 - val_accuracy: 0.0657 - val_binary_accuracy: 0.9454\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 203s 33ms/step - loss: 0.1396 - accuracy: 0.0661 - binary_accuracy: 0.9456 - val_loss: 0.2666 - val_accuracy: 0.0664 - val_binary_accuracy: 0.9457\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 238s 38ms/step - loss: 0.1387 - accuracy: 0.0668 - binary_accuracy: 0.9458 - val_loss: 0.2100 - val_accuracy: 0.0668 - val_binary_accuracy: 0.9459\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 210s 34ms/step - loss: 0.1386 - accuracy: 0.0669 - binary_accuracy: 0.9461 - val_loss: 0.2461 - val_accuracy: 0.0672 - val_binary_accuracy: 0.9461\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 222s 36ms/step - loss: 0.1383 - accuracy: 0.0674 - binary_accuracy: 0.9462 - val_loss: 0.2579 - val_accuracy: 0.0677 - val_binary_accuracy: 0.9463\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 192s 31ms/step - loss: 0.1388 - accuracy: 0.0679 - binary_accuracy: 0.9464 - val_loss: 0.2880 - val_accuracy: 0.0683 - val_binary_accuracy: 0.9465\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 207s 33ms/step - loss: 0.1381 - accuracy: 0.0686 - binary_accuracy: 0.9466 - val_loss: 0.2394 - val_accuracy: 0.0689 - val_binary_accuracy: 0.9467\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 219s 35ms/step - loss: 0.1383 - accuracy: 0.0691 - binary_accuracy: 0.9468 - val_loss: 0.2207 - val_accuracy: 0.0692 - val_binary_accuracy: 0.9469\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 226s 37ms/step - loss: 0.1385 - accuracy: 0.0692 - binary_accuracy: 0.9471 - val_loss: 0.2387 - val_accuracy: 0.0694 - val_binary_accuracy: 0.9471\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 215s 35ms/step - loss: 0.1388 - accuracy: 0.0695 - binary_accuracy: 0.9472 - val_loss: 0.2338 - val_accuracy: 0.0696 - val_binary_accuracy: 0.9472\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 216s 35ms/step - loss: 0.1381 - accuracy: 0.0696 - binary_accuracy: 0.9473 - val_loss: 0.1934 - val_accuracy: 0.0696 - val_binary_accuracy: 0.9474\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
      "6201/6201 [==============================] - 207s 33ms/step - loss: 0.1381 - accuracy: 0.0696 - binary_accuracy: 0.9475 - val_loss: 0.2169 - val_accuracy: 0.0697 - val_binary_accuracy: 0.9476\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.0000000474974515e-06.\n",
      "6201/6201 [==============================] - 208s 34ms/step - loss: 0.1380 - accuracy: 0.0698 - binary_accuracy: 0.9476 - val_loss: 0.2118 - val_accuracy: 0.0699 - val_binary_accuracy: 0.9477\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 226s 36ms/step - loss: 0.1374 - accuracy: 0.0700 - binary_accuracy: 0.9478 - val_loss: 0.2112 - val_accuracy: 0.0700 - val_binary_accuracy: 0.9479\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 224s 36ms/step - loss: 0.1370 - accuracy: 0.0701 - binary_accuracy: 0.9479 - val_loss: 0.2130 - val_accuracy: 0.0701 - val_binary_accuracy: 0.9480\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 194s 31ms/step - loss: 0.1381 - accuracy: 0.0702 - binary_accuracy: 0.9481 - val_loss: 0.2267 - val_accuracy: 0.0703 - val_binary_accuracy: 0.9481\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 199s 32ms/step - loss: 0.1374 - accuracy: 0.0704 - binary_accuracy: 0.9482 - val_loss: 0.2162 - val_accuracy: 0.0704 - val_binary_accuracy: 0.9482\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 220s 36ms/step - loss: 0.1378 - accuracy: 0.0705 - binary_accuracy: 0.9482 - val_loss: 0.2154 - val_accuracy: 0.0705 - val_binary_accuracy: 0.9484\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 218s 35ms/step - loss: 0.1373 - accuracy: 0.0706 - binary_accuracy: 0.9484 - val_loss: 0.2203 - val_accuracy: 0.0707 - val_binary_accuracy: 0.9485\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 235s 38ms/step - loss: 0.1381 - accuracy: 0.0707 - binary_accuracy: 0.9486 - val_loss: 0.2227 - val_accuracy: 0.0708 - val_binary_accuracy: 0.9486\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 246s 40ms/step - loss: 0.1377 - accuracy: 0.0709 - binary_accuracy: 0.9487 - val_loss: 0.2209 - val_accuracy: 0.0709 - val_binary_accuracy: 0.9487\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 197s 32ms/step - loss: 0.1378 - accuracy: 0.0710 - binary_accuracy: 0.9487 - val_loss: 0.2209 - val_accuracy: 0.0710 - val_binary_accuracy: 0.9488\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 183s 29ms/step - loss: 0.1368 - accuracy: 0.0710 - binary_accuracy: 0.9488 - val_loss: 0.2201 - val_accuracy: 0.0710 - val_binary_accuracy: 0.9489\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 184s 30ms/step - loss: 0.1376 - accuracy: 0.0711 - binary_accuracy: 0.9489 - val_loss: 0.2256 - val_accuracy: 0.0711 - val_binary_accuracy: 0.9490\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 183s 30ms/step - loss: 0.1370 - accuracy: 0.0712 - binary_accuracy: 0.9490 - val_loss: 0.2141 - val_accuracy: 0.0712 - val_binary_accuracy: 0.9490\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 213s 34ms/step - loss: 0.1373 - accuracy: 0.0712 - binary_accuracy: 0.9491 - val_loss: 0.2192 - val_accuracy: 0.0713 - val_binary_accuracy: 0.9491\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 221s 36ms/step - loss: 0.1366 - accuracy: 0.0713 - binary_accuracy: 0.9492 - val_loss: 0.2191 - val_accuracy: 0.0714 - val_binary_accuracy: 0.9492\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 217s 35ms/step - loss: 0.1381 - accuracy: 0.0714 - binary_accuracy: 0.9492 - val_loss: 0.2115 - val_accuracy: 0.0714 - val_binary_accuracy: 0.9493\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 185s 30ms/step - loss: 0.1375 - accuracy: 0.0715 - binary_accuracy: 0.9493 - val_loss: 0.2131 - val_accuracy: 0.0715 - val_binary_accuracy: 0.9494\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 192s 31ms/step - loss: 0.1373 - accuracy: 0.0715 - binary_accuracy: 0.9494 - val_loss: 0.2156 - val_accuracy: 0.0716 - val_binary_accuracy: 0.9495\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 203s 33ms/step - loss: 0.1368 - accuracy: 0.0716 - binary_accuracy: 0.9495 - val_loss: 0.2168 - val_accuracy: 0.0716 - val_binary_accuracy: 0.9495\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 9.999999974752427e-07.\n",
      "6201/6201 [==============================] - 203s 33ms/step - loss: 0.1368 - accuracy: 0.0716 - binary_accuracy: 0.9496 - val_loss: 0.2265 - val_accuracy: 0.0717 - val_binary_accuracy: 0.9496\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 9.99999997475243e-10.\n",
      "6201/6201 [==============================] - 206s 33ms/step - loss: 0.1377 - accuracy: 0.0717 - binary_accuracy: 0.9497 - val_loss: 0.2220 - val_accuracy: 0.0717 - val_binary_accuracy: 0.9497\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 195s 31ms/step - loss: 0.1371 - accuracy: 0.0718 - binary_accuracy: 0.9497 - val_loss: 0.2191 - val_accuracy: 0.0718 - val_binary_accuracy: 0.9497\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 188s 30ms/step - loss: 0.1370 - accuracy: 0.0718 - binary_accuracy: 0.9497 - val_loss: 0.2215 - val_accuracy: 0.0719 - val_binary_accuracy: 0.9498\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 190s 31ms/step - loss: 0.1371 - accuracy: 0.0719 - binary_accuracy: 0.9498 - val_loss: 0.2192 - val_accuracy: 0.0719 - val_binary_accuracy: 0.9499\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 317s 51ms/step - loss: 0.1371 - accuracy: 0.0719 - binary_accuracy: 0.9498 - val_loss: 0.2126 - val_accuracy: 0.0719 - val_binary_accuracy: 0.9499\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 206s 33ms/step - loss: 0.1378 - accuracy: 0.0719 - binary_accuracy: 0.9500 - val_loss: 0.2257 - val_accuracy: 0.0720 - val_binary_accuracy: 0.9500\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 198s 32ms/step - loss: 0.1380 - accuracy: 0.0720 - binary_accuracy: 0.9500 - val_loss: 0.2201 - val_accuracy: 0.0720 - val_binary_accuracy: 0.9500\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 187s 30ms/step - loss: 0.1372 - accuracy: 0.0720 - binary_accuracy: 0.9501 - val_loss: 0.2128 - val_accuracy: 0.0721 - val_binary_accuracy: 0.9501\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 187s 30ms/step - loss: 0.1378 - accuracy: 0.0721 - binary_accuracy: 0.9502 - val_loss: 0.2173 - val_accuracy: 0.0721 - val_binary_accuracy: 0.9501\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 186s 30ms/step - loss: 0.1368 - accuracy: 0.0721 - binary_accuracy: 0.9502 - val_loss: 0.2326 - val_accuracy: 0.0721 - val_binary_accuracy: 0.9502\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 188s 30ms/step - loss: 0.1378 - accuracy: 0.0722 - binary_accuracy: 0.9502 - val_loss: 0.2150 - val_accuracy: 0.0722 - val_binary_accuracy: 0.9502\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 529s 85ms/step - loss: 0.1371 - accuracy: 0.0722 - binary_accuracy: 0.9502 - val_loss: 0.2197 - val_accuracy: 0.0722 - val_binary_accuracy: 0.9503\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 204s 33ms/step - loss: 0.1372 - accuracy: 0.0722 - binary_accuracy: 0.9502 - val_loss: 0.2176 - val_accuracy: 0.0722 - val_binary_accuracy: 0.9503\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 196s 32ms/step - loss: 0.1371 - accuracy: 0.0723 - binary_accuracy: 0.9503 - val_loss: 0.2169 - val_accuracy: 0.0723 - val_binary_accuracy: 0.9504\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 198s 32ms/step - loss: 0.1380 - accuracy: 0.0723 - binary_accuracy: 0.9504 - val_loss: 0.2173 - val_accuracy: 0.0723 - val_binary_accuracy: 0.9504\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 207s 33ms/step - loss: 0.1376 - accuracy: 0.0723 - binary_accuracy: 0.9505 - val_loss: 0.2168 - val_accuracy: 0.0723 - val_binary_accuracy: 0.9505\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 214s 35ms/step - loss: 0.1374 - accuracy: 0.0723 - binary_accuracy: 0.9505 - val_loss: 0.2232 - val_accuracy: 0.0723 - val_binary_accuracy: 0.9505\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 213s 34ms/step - loss: 0.1382 - accuracy: 0.0724 - binary_accuracy: 0.9505 - val_loss: 0.2113 - val_accuracy: 0.0724 - val_binary_accuracy: 0.9505\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 211s 34ms/step - loss: 0.1375 - accuracy: 0.0724 - binary_accuracy: 0.9506 - val_loss: 0.2226 - val_accuracy: 0.0724 - val_binary_accuracy: 0.9506\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 9.999999717180685e-10.\n",
      "6201/6201 [==============================] - 204s 33ms/step - loss: 0.1386 - accuracy: 0.0724 - binary_accuracy: 0.9506 - val_loss: 0.2139 - val_accuracy: 0.0724 - val_binary_accuracy: 0.9506\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 9.999999717180687e-14.\n",
      "6201/6201 [==============================] - 205s 33ms/step - loss: 0.1376 - accuracy: 0.0724 - binary_accuracy: 0.9507 - val_loss: 0.2162 - val_accuracy: 0.0724 - val_binary_accuracy: 0.9507\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 207s 33ms/step - loss: 0.1371 - accuracy: 0.0724 - binary_accuracy: 0.9507 - val_loss: 0.2182 - val_accuracy: 0.0724 - val_binary_accuracy: 0.9508\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 208s 34ms/step - loss: 0.1378 - accuracy: 0.0724 - binary_accuracy: 0.9508 - val_loss: 0.2147 - val_accuracy: 0.0725 - val_binary_accuracy: 0.9508\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 217s 35ms/step - loss: 0.1372 - accuracy: 0.0725 - binary_accuracy: 0.9508 - val_loss: 0.2201 - val_accuracy: 0.0725 - val_binary_accuracy: 0.9509\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 1979s 319ms/step - loss: 0.1377 - accuracy: 0.0725 - binary_accuracy: 0.9510 - val_loss: 0.2129 - val_accuracy: 0.0725 - val_binary_accuracy: 0.9510\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 229s 37ms/step - loss: 0.1377 - accuracy: 0.0725 - binary_accuracy: 0.9510 - val_loss: 0.2145 - val_accuracy: 0.0725 - val_binary_accuracy: 0.9511\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 205s 33ms/step - loss: 0.1379 - accuracy: 0.0725 - binary_accuracy: 0.9511 - val_loss: 0.2257 - val_accuracy: 0.0725 - val_binary_accuracy: 0.9511\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 234s 38ms/step - loss: 0.1376 - accuracy: 0.0726 - binary_accuracy: 0.9512 - val_loss: 0.2123 - val_accuracy: 0.0726 - val_binary_accuracy: 0.9512\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 223s 36ms/step - loss: 0.1374 - accuracy: 0.0726 - binary_accuracy: 0.9512 - val_loss: 0.2194 - val_accuracy: 0.0726 - val_binary_accuracy: 0.9513\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 262s 42ms/step - loss: 0.1379 - accuracy: 0.0726 - binary_accuracy: 0.9513 - val_loss: 0.2148 - val_accuracy: 0.0727 - val_binary_accuracy: 0.9513\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 267s 43ms/step - loss: 0.1372 - accuracy: 0.0727 - binary_accuracy: 0.9513 - val_loss: 0.2106 - val_accuracy: 0.0727 - val_binary_accuracy: 0.9514\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 261s 42ms/step - loss: 0.1374 - accuracy: 0.0727 - binary_accuracy: 0.9515 - val_loss: 0.2222 - val_accuracy: 0.0727 - val_binary_accuracy: 0.9515\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 241s 39ms/step - loss: 0.1378 - accuracy: 0.0727 - binary_accuracy: 0.9515 - val_loss: 0.2295 - val_accuracy: 0.0727 - val_binary_accuracy: 0.9515\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 274s 44ms/step - loss: 0.1368 - accuracy: 0.0728 - binary_accuracy: 0.9516 - val_loss: 0.2156 - val_accuracy: 0.0728 - val_binary_accuracy: 0.9516\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 1244s 201ms/step - loss: 0.1380 - accuracy: 0.0728 - binary_accuracy: 0.9516 - val_loss: 0.2154 - val_accuracy: 0.0728 - val_binary_accuracy: 0.9517\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 813s 131ms/step - loss: 0.1384 - accuracy: 0.0728 - binary_accuracy: 0.9517 - val_loss: 0.2158 - val_accuracy: 0.0728 - val_binary_accuracy: 0.9517\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 217s 35ms/step - loss: 0.1374 - accuracy: 0.0728 - binary_accuracy: 0.9517 - val_loss: 0.2132 - val_accuracy: 0.0728 - val_binary_accuracy: 0.9518\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 228s 37ms/step - loss: 0.1374 - accuracy: 0.0728 - binary_accuracy: 0.9518 - val_loss: 0.2205 - val_accuracy: 0.0728 - val_binary_accuracy: 0.9518\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 245s 39ms/step - loss: 0.1376 - accuracy: 0.0729 - binary_accuracy: 0.9518 - val_loss: 0.2294 - val_accuracy: 0.0729 - val_binary_accuracy: 0.9519\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 9.9999998245167e-14.\n",
      "6201/6201 [==============================] - 249s 40ms/step - loss: 0.1373 - accuracy: 0.0729 - binary_accuracy: 0.9518 - val_loss: 0.2126 - val_accuracy: 0.0730 - val_binary_accuracy: 0.9519\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 9.999999824516702e-19.\n",
      "6201/6201 [==============================] - 237s 38ms/step - loss: 0.1385 - accuracy: 0.0730 - binary_accuracy: 0.9520 - val_loss: 0.2189 - val_accuracy: 0.0730 - val_binary_accuracy: 0.9520\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 214s 34ms/step - loss: 0.1383 - accuracy: 0.0730 - binary_accuracy: 0.9520 - val_loss: 0.2226 - val_accuracy: 0.0730 - val_binary_accuracy: 0.9520\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 208s 34ms/step - loss: 0.1375 - accuracy: 0.0730 - binary_accuracy: 0.9521 - val_loss: 0.2208 - val_accuracy: 0.0731 - val_binary_accuracy: 0.9521\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 219s 35ms/step - loss: 0.1369 - accuracy: 0.0731 - binary_accuracy: 0.9521 - val_loss: 0.2268 - val_accuracy: 0.0731 - val_binary_accuracy: 0.9521\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 193s 31ms/step - loss: 0.1370 - accuracy: 0.0731 - binary_accuracy: 0.9521 - val_loss: 0.2191 - val_accuracy: 0.0731 - val_binary_accuracy: 0.9521\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 187s 30ms/step - loss: 0.1380 - accuracy: 0.0731 - binary_accuracy: 0.9521 - val_loss: 0.2133 - val_accuracy: 0.0731 - val_binary_accuracy: 0.9522\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 186s 30ms/step - loss: 0.1384 - accuracy: 0.0731 - binary_accuracy: 0.9522 - val_loss: 0.2244 - val_accuracy: 0.0731 - val_binary_accuracy: 0.9523\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 633s 102ms/step - loss: 0.1379 - accuracy: 0.0731 - binary_accuracy: 0.9523 - val_loss: 0.2171 - val_accuracy: 0.0731 - val_binary_accuracy: 0.9523\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 228s 37ms/step - loss: 0.1372 - accuracy: 0.0731 - binary_accuracy: 0.9523 - val_loss: 0.2171 - val_accuracy: 0.0731 - val_binary_accuracy: 0.9523\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 214s 34ms/step - loss: 0.1381 - accuracy: 0.0731 - binary_accuracy: 0.9523 - val_loss: 0.2125 - val_accuracy: 0.0732 - val_binary_accuracy: 0.9524\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 232s 37ms/step - loss: 0.1374 - accuracy: 0.0732 - binary_accuracy: 0.9525 - val_loss: 0.2175 - val_accuracy: 0.0732 - val_binary_accuracy: 0.9524\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 226s 36ms/step - loss: 0.1372 - accuracy: 0.0732 - binary_accuracy: 0.9525 - val_loss: 0.2100 - val_accuracy: 0.0732 - val_binary_accuracy: 0.9525\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 221s 36ms/step - loss: 0.1376 - accuracy: 0.0732 - binary_accuracy: 0.9525 - val_loss: 0.2167 - val_accuracy: 0.0732 - val_binary_accuracy: 0.9525\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 201s 32ms/step - loss: 0.1371 - accuracy: 0.0732 - binary_accuracy: 0.9526 - val_loss: 0.2229 - val_accuracy: 0.0732 - val_binary_accuracy: 0.9526\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 221s 36ms/step - loss: 0.1373 - accuracy: 0.0732 - binary_accuracy: 0.9526 - val_loss: 0.2219 - val_accuracy: 0.0732 - val_binary_accuracy: 0.9526\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 218s 35ms/step - loss: 0.1363 - accuracy: 0.0732 - binary_accuracy: 0.9526 - val_loss: 0.2133 - val_accuracy: 0.0732 - val_binary_accuracy: 0.9526\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 219s 35ms/step - loss: 0.1379 - accuracy: 0.0732 - binary_accuracy: 0.9526 - val_loss: 0.2228 - val_accuracy: 0.0732 - val_binary_accuracy: 0.9527\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 189s 30ms/step - loss: 0.1371 - accuracy: 0.0733 - binary_accuracy: 0.9526 - val_loss: 0.2136 - val_accuracy: 0.0733 - val_binary_accuracy: 0.9527\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 183s 29ms/step - loss: 0.1368 - accuracy: 0.0733 - binary_accuracy: 0.9527 - val_loss: 0.2160 - val_accuracy: 0.0733 - val_binary_accuracy: 0.9528\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 9.999999424161284e-19.\n",
      "6201/6201 [==============================] - 193s 31ms/step - loss: 0.1374 - accuracy: 0.0733 - binary_accuracy: 0.9528 - val_loss: 0.2236 - val_accuracy: 0.0733 - val_binary_accuracy: 0.9528\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 9.999999424161287e-25.\n",
      "6201/6201 [==============================] - 188s 30ms/step - loss: 0.1379 - accuracy: 0.0733 - binary_accuracy: 0.9528 - val_loss: 0.2177 - val_accuracy: 0.0733 - val_binary_accuracy: 0.9528\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 202s 33ms/step - loss: 0.1376 - accuracy: 0.0733 - binary_accuracy: 0.9528 - val_loss: 0.2125 - val_accuracy: 0.0733 - val_binary_accuracy: 0.9529\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 225s 36ms/step - loss: 0.1365 - accuracy: 0.0733 - binary_accuracy: 0.9530 - val_loss: 0.2259 - val_accuracy: 0.0733 - val_binary_accuracy: 0.9529\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 838s 135ms/step - loss: 0.1379 - accuracy: 0.0733 - binary_accuracy: 0.9530 - val_loss: 0.2151 - val_accuracy: 0.0733 - val_binary_accuracy: 0.9529\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 188s 30ms/step - loss: 0.1369 - accuracy: 0.0733 - binary_accuracy: 0.9530 - val_loss: 0.2132 - val_accuracy: 0.0733 - val_binary_accuracy: 0.9530\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 184s 30ms/step - loss: 0.1373 - accuracy: 0.0733 - binary_accuracy: 0.9530 - val_loss: 0.2168 - val_accuracy: 0.0733 - val_binary_accuracy: 0.9530\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 190s 31ms/step - loss: 0.1380 - accuracy: 0.0734 - binary_accuracy: 0.9531 - val_loss: 0.2186 - val_accuracy: 0.0734 - val_binary_accuracy: 0.9530\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 207s 33ms/step - loss: 0.1371 - accuracy: 0.0734 - binary_accuracy: 0.9531 - val_loss: 0.2230 - val_accuracy: 0.0734 - val_binary_accuracy: 0.9531\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 214s 34ms/step - loss: 0.1376 - accuracy: 0.0734 - binary_accuracy: 0.9531 - val_loss: 0.2148 - val_accuracy: 0.0734 - val_binary_accuracy: 0.9531\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 221s 36ms/step - loss: 0.1382 - accuracy: 0.0734 - binary_accuracy: 0.9531 - val_loss: 0.2120 - val_accuracy: 0.0734 - val_binary_accuracy: 0.9531\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 236s 38ms/step - loss: 0.1372 - accuracy: 0.0734 - binary_accuracy: 0.9531 - val_loss: 0.2205 - val_accuracy: 0.0734 - val_binary_accuracy: 0.9531\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 229s 37ms/step - loss: 0.1372 - accuracy: 0.0734 - binary_accuracy: 0.9531 - val_loss: 0.2145 - val_accuracy: 0.0734 - val_binary_accuracy: 0.9532\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 234s 38ms/step - loss: 0.1374 - accuracy: 0.0734 - binary_accuracy: 0.9531 - val_loss: 0.2236 - val_accuracy: 0.0734 - val_binary_accuracy: 0.9532\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 230s 37ms/step - loss: 0.1371 - accuracy: 0.0734 - binary_accuracy: 0.9532 - val_loss: 0.2172 - val_accuracy: 0.0734 - val_binary_accuracy: 0.9532\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 228s 37ms/step - loss: 0.1374 - accuracy: 0.0734 - binary_accuracy: 0.9532 - val_loss: 0.2219 - val_accuracy: 0.0734 - val_binary_accuracy: 0.9533\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 270s 44ms/step - loss: 0.1368 - accuracy: 0.0735 - binary_accuracy: 0.9533 - val_loss: 0.2152 - val_accuracy: 0.0735 - val_binary_accuracy: 0.9533\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 310s 50ms/step - loss: 0.1377 - accuracy: 0.0735 - binary_accuracy: 0.9533 - val_loss: 0.2177 - val_accuracy: 0.0735 - val_binary_accuracy: 0.9533\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 248s 40ms/step - loss: 0.1379 - accuracy: 0.0735 - binary_accuracy: 0.9533 - val_loss: 0.2260 - val_accuracy: 0.0735 - val_binary_accuracy: 0.9533\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 264s 43ms/step - loss: 0.1364 - accuracy: 0.0735 - binary_accuracy: 0.9533 - val_loss: 0.2247 - val_accuracy: 0.0735 - val_binary_accuracy: 0.9534\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 9.999999209338682e-25.\n",
      "6201/6201 [==============================] - 167s 27ms/step - loss: 0.1376 - accuracy: 0.0735 - binary_accuracy: 0.9534 - val_loss: 0.2229 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9534\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 9.999999209338686e-32.\n",
      "6201/6201 [==============================] - 201s 32ms/step - loss: 0.1373 - accuracy: 0.0736 - binary_accuracy: 0.9534 - val_loss: 0.2178 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9534\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 267s 43ms/step - loss: 0.1374 - accuracy: 0.0736 - binary_accuracy: 0.9535 - val_loss: 0.2222 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9534\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 262s 42ms/step - loss: 0.1378 - accuracy: 0.0736 - binary_accuracy: 0.9535 - val_loss: 0.2240 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9535\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 28169s 5s/step - loss: 0.1372 - accuracy: 0.0736 - binary_accuracy: 0.9535 - val_loss: 0.2166 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9535\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 5229s 843ms/step - loss: 0.1379 - accuracy: 0.0736 - binary_accuracy: 0.9536 - val_loss: 0.2178 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9535\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 209s 34ms/step - loss: 0.1376 - accuracy: 0.0736 - binary_accuracy: 0.9536 - val_loss: 0.2202 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9536\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 159s 26ms/step - loss: 0.1382 - accuracy: 0.0736 - binary_accuracy: 0.9536 - val_loss: 0.2272 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9536\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 124s 20ms/step - loss: 0.1376 - accuracy: 0.0736 - binary_accuracy: 0.9536 - val_loss: 0.2162 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9536\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 121s 20ms/step - loss: 0.1365 - accuracy: 0.0736 - binary_accuracy: 0.9536 - val_loss: 0.2152 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9536\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 134s 22ms/step - loss: 0.1374 - accuracy: 0.0736 - binary_accuracy: 0.9536 - val_loss: 0.2191 - val_accuracy: 0.0736 - val_binary_accuracy: 0.9537\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 127s 21ms/step - loss: 0.1372 - accuracy: 0.0737 - binary_accuracy: 0.9536 - val_loss: 0.2236 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9537\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 129s 21ms/step - loss: 0.1377 - accuracy: 0.0737 - binary_accuracy: 0.9536 - val_loss: 0.2178 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9537\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 130s 21ms/step - loss: 0.1389 - accuracy: 0.0737 - binary_accuracy: 0.9536 - val_loss: 0.2140 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9537\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 141s 23ms/step - loss: 0.1375 - accuracy: 0.0737 - binary_accuracy: 0.9537 - val_loss: 0.2136 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9537\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1365 - accuracy: 0.0737 - binary_accuracy: 0.9537 - val_loss: 0.2136 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9538\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 118s 19ms/step - loss: 0.1376 - accuracy: 0.0737 - binary_accuracy: 0.9537 - val_loss: 0.2150 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9538\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1361 - accuracy: 0.0737 - binary_accuracy: 0.9537 - val_loss: 0.2181 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9538\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1379 - accuracy: 0.0737 - binary_accuracy: 0.9538 - val_loss: 0.2192 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9538\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1368 - accuracy: 0.0737 - binary_accuracy: 0.9538 - val_loss: 0.2203 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9539\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 9.999999796611898e-32.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1379 - accuracy: 0.0737 - binary_accuracy: 0.9539 - val_loss: 0.2174 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9539\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 9.999999796611903e-40.\n",
      "6201/6201 [==============================] - 119s 19ms/step - loss: 0.1379 - accuracy: 0.0737 - binary_accuracy: 0.9539 - val_loss: 0.2178 - val_accuracy: 0.0737 - val_binary_accuracy: 0.9540\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1380 - accuracy: 0.0738 - binary_accuracy: 0.9541 - val_loss: 0.2218 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9540\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1369 - accuracy: 0.0738 - binary_accuracy: 0.9541 - val_loss: 0.2074 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9541\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1369 - accuracy: 0.0738 - binary_accuracy: 0.9541 - val_loss: 0.2180 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9542\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1383 - accuracy: 0.0738 - binary_accuracy: 0.9542 - val_loss: 0.2227 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9543\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 115s 18ms/step - loss: 0.1374 - accuracy: 0.0738 - binary_accuracy: 0.9544 - val_loss: 0.2160 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9544\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1384 - accuracy: 0.0738 - binary_accuracy: 0.9544 - val_loss: 0.2193 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9544\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 120s 19ms/step - loss: 0.1376 - accuracy: 0.0738 - binary_accuracy: 0.9545 - val_loss: 0.2160 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9545\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1373 - accuracy: 0.0738 - binary_accuracy: 0.9546 - val_loss: 0.2228 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9546\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 118s 19ms/step - loss: 0.1372 - accuracy: 0.0738 - binary_accuracy: 0.9546 - val_loss: 0.2199 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9547\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 119s 19ms/step - loss: 0.1371 - accuracy: 0.0738 - binary_accuracy: 0.9546 - val_loss: 0.2072 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9547\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 127s 20ms/step - loss: 0.1380 - accuracy: 0.0738 - binary_accuracy: 0.9547 - val_loss: 0.2193 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9548\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 140s 23ms/step - loss: 0.1386 - accuracy: 0.0738 - binary_accuracy: 0.9549 - val_loss: 0.2209 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9549\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 164s 26ms/step - loss: 0.1366 - accuracy: 0.0738 - binary_accuracy: 0.9549 - val_loss: 0.2203 - val_accuracy: 0.0738 - val_binary_accuracy: 0.9550\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 181s 29ms/step - loss: 0.1372 - accuracy: 0.0738 - binary_accuracy: 0.9550 - val_loss: 0.2254 - val_accuracy: 0.0739 - val_binary_accuracy: 0.9550\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 220s 36ms/step - loss: 0.1373 - accuracy: 0.0739 - binary_accuracy: 0.9551 - val_loss: 0.2133 - val_accuracy: 0.0739 - val_binary_accuracy: 0.9551\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 233s 38ms/step - loss: 0.1377 - accuracy: 0.0739 - binary_accuracy: 0.9551 - val_loss: 0.2229 - val_accuracy: 0.0739 - val_binary_accuracy: 0.9552\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 185s 30ms/step - loss: 0.1382 - accuracy: 0.0739 - binary_accuracy: 0.9551 - val_loss: 0.2330 - val_accuracy: 0.0739 - val_binary_accuracy: 0.9552\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 182s 29ms/step - loss: 0.1372 - accuracy: 0.0739 - binary_accuracy: 0.9552 - val_loss: 0.2098 - val_accuracy: 0.0739 - val_binary_accuracy: 0.9553\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 1.0000002153053333e-39.\n",
      "6201/6201 [==============================] - 152s 24ms/step - loss: 0.1372 - accuracy: 0.0739 - binary_accuracy: 0.9554 - val_loss: 0.2232 - val_accuracy: 0.0740 - val_binary_accuracy: 0.9554\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 1.0000002153053338e-48.\n",
      "6201/6201 [==============================] - 174s 28ms/step - loss: 0.1380 - accuracy: 0.0740 - binary_accuracy: 0.9554 - val_loss: 0.2213 - val_accuracy: 0.0740 - val_binary_accuracy: 0.9554\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 169s 27ms/step - loss: 0.1374 - accuracy: 0.0740 - binary_accuracy: 0.9555 - val_loss: 0.2247 - val_accuracy: 0.0740 - val_binary_accuracy: 0.9555\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 161s 26ms/step - loss: 0.1385 - accuracy: 0.0740 - binary_accuracy: 0.9556 - val_loss: 0.2291 - val_accuracy: 0.0740 - val_binary_accuracy: 0.9556\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 195s 31ms/step - loss: 0.1369 - accuracy: 0.0740 - binary_accuracy: 0.9556 - val_loss: 0.2244 - val_accuracy: 0.0740 - val_binary_accuracy: 0.9556\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 202s 33ms/step - loss: 0.1369 - accuracy: 0.0740 - binary_accuracy: 0.9556 - val_loss: 0.2231 - val_accuracy: 0.0740 - val_binary_accuracy: 0.9557\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 182s 29ms/step - loss: 0.1374 - accuracy: 0.0740 - binary_accuracy: 0.9557 - val_loss: 0.2184 - val_accuracy: 0.0740 - val_binary_accuracy: 0.9557\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 2306s 372ms/step - loss: 0.1375 - accuracy: 0.0740 - binary_accuracy: 0.9557 - val_loss: 0.2185 - val_accuracy: 0.0740 - val_binary_accuracy: 0.9558\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 186s 30ms/step - loss: 0.1376 - accuracy: 0.0741 - binary_accuracy: 0.9559 - val_loss: 0.2210 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9559\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 154s 25ms/step - loss: 0.1374 - accuracy: 0.0741 - binary_accuracy: 0.9559 - val_loss: 0.2148 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9559\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 177s 28ms/step - loss: 0.1372 - accuracy: 0.0741 - binary_accuracy: 0.9560 - val_loss: 0.2115 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9560\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 171s 27ms/step - loss: 0.1380 - accuracy: 0.0741 - binary_accuracy: 0.9560 - val_loss: 0.2150 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9560\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 153s 25ms/step - loss: 0.1379 - accuracy: 0.0741 - binary_accuracy: 0.9561 - val_loss: 0.2250 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9561\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 135s 22ms/step - loss: 0.1376 - accuracy: 0.0741 - binary_accuracy: 0.9561 - val_loss: 0.2172 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9562\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 133s 21ms/step - loss: 0.1381 - accuracy: 0.0741 - binary_accuracy: 0.9562 - val_loss: 0.2190 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9562\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1373 - accuracy: 0.0741 - binary_accuracy: 0.9562 - val_loss: 0.2225 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9563\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1373 - accuracy: 0.0741 - binary_accuracy: 0.9564 - val_loss: 0.2182 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9563\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1380 - accuracy: 0.0741 - binary_accuracy: 0.9564 - val_loss: 0.2262 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9564\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1375 - accuracy: 0.0741 - binary_accuracy: 0.9564 - val_loss: 0.2163 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9564\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1377 - accuracy: 0.0741 - binary_accuracy: 0.9565 - val_loss: 0.2236 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9565\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1371 - accuracy: 0.0741 - binary_accuracy: 0.9565 - val_loss: 0.2233 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9565\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1376 - accuracy: 0.0741 - binary_accuracy: 0.9565 - val_loss: 0.2197 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9566\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1383 - accuracy: 0.0741 - binary_accuracy: 0.9566 - val_loss: 0.2113 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9566\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 113s 18ms/step - loss: 0.1375 - accuracy: 0.0741 - binary_accuracy: 0.9567 - val_loss: 0.2204 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9567\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1372 - accuracy: 0.0741 - binary_accuracy: 0.9567 - val_loss: 0.2132 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9568\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1377 - accuracy: 0.0741 - binary_accuracy: 0.9569 - val_loss: 0.2215 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9568\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1371 - accuracy: 0.0741 - binary_accuracy: 0.9569 - val_loss: 0.2114 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9569\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1367 - accuracy: 0.0741 - binary_accuracy: 0.9569 - val_loss: 0.2285 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9569\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1371 - accuracy: 0.0741 - binary_accuracy: 0.9570 - val_loss: 0.2085 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9570\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1370 - accuracy: 0.0741 - binary_accuracy: 0.9570 - val_loss: 0.2118 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9570\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1370 - accuracy: 0.0741 - binary_accuracy: 0.9570 - val_loss: 0.2128 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9571\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 113s 18ms/step - loss: 0.1375 - accuracy: 0.0741 - binary_accuracy: 0.9571 - val_loss: 0.2217 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9571\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 1066s 172ms/step - loss: 0.1380 - accuracy: 0.0741 - binary_accuracy: 0.9571 - val_loss: 0.2160 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9572\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 1317s 212ms/step - loss: 0.1370 - accuracy: 0.0741 - binary_accuracy: 0.9572 - val_loss: 0.2217 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9572\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 19ms/step - loss: 0.1368 - accuracy: 0.0741 - binary_accuracy: 0.9572 - val_loss: 0.2193 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9573\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1375 - accuracy: 0.0741 - binary_accuracy: 0.9574 - val_loss: 0.2246 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9573\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 113s 18ms/step - loss: 0.1369 - accuracy: 0.0741 - binary_accuracy: 0.9574 - val_loss: 0.2191 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9574\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1381 - accuracy: 0.0741 - binary_accuracy: 0.9574 - val_loss: 0.2241 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9574\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1383 - accuracy: 0.0741 - binary_accuracy: 0.9575 - val_loss: 0.2205 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9575\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1379 - accuracy: 0.0741 - binary_accuracy: 0.9575 - val_loss: 0.2244 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9575\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 118s 19ms/step - loss: 0.1372 - accuracy: 0.0742 - binary_accuracy: 0.9575 - val_loss: 0.2102 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9576\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 19ms/step - loss: 0.1370 - accuracy: 0.0742 - binary_accuracy: 0.9575 - val_loss: 0.2218 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9576\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1377 - accuracy: 0.0742 - binary_accuracy: 0.9576 - val_loss: 0.2125 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9576\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1375 - accuracy: 0.0742 - binary_accuracy: 0.9576 - val_loss: 0.2156 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9577\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 18ms/step - loss: 0.1374 - accuracy: 0.0742 - binary_accuracy: 0.9577 - val_loss: 0.2182 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9577\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1373 - accuracy: 0.0742 - binary_accuracy: 0.9577 - val_loss: 0.2067 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9578\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 113s 18ms/step - loss: 0.1381 - accuracy: 0.0741 - binary_accuracy: 0.9578 - val_loss: 0.2161 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9578\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 119s 19ms/step - loss: 0.1371 - accuracy: 0.0741 - binary_accuracy: 0.9578 - val_loss: 0.2228 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9578\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 19ms/step - loss: 0.1365 - accuracy: 0.0741 - binary_accuracy: 0.9579 - val_loss: 0.2254 - val_accuracy: 0.0741 - val_binary_accuracy: 0.9579\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1367 - accuracy: 0.0741 - binary_accuracy: 0.9580 - val_loss: 0.2200 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9579\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 119s 19ms/step - loss: 0.1367 - accuracy: 0.0742 - binary_accuracy: 0.9580 - val_loss: 0.2159 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9580\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1373 - accuracy: 0.0742 - binary_accuracy: 0.9580 - val_loss: 0.2158 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9580\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 1848s 298ms/step - loss: 0.1377 - accuracy: 0.0742 - binary_accuracy: 0.9580 - val_loss: 0.2154 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9581\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 788s 127ms/step - loss: 0.1368 - accuracy: 0.0742 - binary_accuracy: 0.9580 - val_loss: 0.2176 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9581\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 113s 18ms/step - loss: 0.1372 - accuracy: 0.0742 - binary_accuracy: 0.9580 - val_loss: 0.2286 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9581\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1378 - accuracy: 0.0742 - binary_accuracy: 0.9581 - val_loss: 0.2180 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9582\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1367 - accuracy: 0.0742 - binary_accuracy: 0.9582 - val_loss: 0.2203 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9582\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 119s 19ms/step - loss: 0.1371 - accuracy: 0.0742 - binary_accuracy: 0.9582 - val_loss: 0.2280 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9583\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 131s 21ms/step - loss: 0.1369 - accuracy: 0.0742 - binary_accuracy: 0.9583 - val_loss: 0.2206 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9583\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 138s 22ms/step - loss: 0.1373 - accuracy: 0.0742 - binary_accuracy: 0.9583 - val_loss: 0.2195 - val_accuracy: 0.0742 - val_binary_accuracy: 0.9583\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 148s 24ms/step - loss: 0.1373 - accuracy: 0.0742 - binary_accuracy: 0.9584 - val_loss: 0.2156 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9584\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 132s 21ms/step - loss: 0.1378 - accuracy: 0.0743 - binary_accuracy: 0.9585 - val_loss: 0.2173 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9584\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1371 - accuracy: 0.0743 - binary_accuracy: 0.9585 - val_loss: 0.2240 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9584\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 118s 19ms/step - loss: 0.1374 - accuracy: 0.0743 - binary_accuracy: 0.9585 - val_loss: 0.2263 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9585\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 120s 19ms/step - loss: 0.1368 - accuracy: 0.0743 - binary_accuracy: 0.9585 - val_loss: 0.2157 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9585\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 18ms/step - loss: 0.1371 - accuracy: 0.0743 - binary_accuracy: 0.9585 - val_loss: 0.2237 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9586\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1372 - accuracy: 0.0743 - binary_accuracy: 0.9585 - val_loss: 0.2179 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9586\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 118s 19ms/step - loss: 0.1375 - accuracy: 0.0743 - binary_accuracy: 0.9585 - val_loss: 0.2131 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9586\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 121s 19ms/step - loss: 0.1372 - accuracy: 0.0743 - binary_accuracy: 0.9586 - val_loss: 0.2125 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9587\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 130s 21ms/step - loss: 0.1379 - accuracy: 0.0743 - binary_accuracy: 0.9586 - val_loss: 0.2261 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9587\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 130s 21ms/step - loss: 0.1378 - accuracy: 0.0743 - binary_accuracy: 0.9587 - val_loss: 0.2294 - val_accuracy: 0.0743 - val_binary_accuracy: 0.9587\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 118s 19ms/step - loss: 0.1373 - accuracy: 0.0743 - binary_accuracy: 0.9588 - val_loss: 0.2214 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9588\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 124s 20ms/step - loss: 0.1375 - accuracy: 0.0744 - binary_accuracy: 0.9588 - val_loss: 0.2162 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9588\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 127s 21ms/step - loss: 0.1380 - accuracy: 0.0744 - binary_accuracy: 0.9588 - val_loss: 0.2290 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9588\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 126s 20ms/step - loss: 0.1378 - accuracy: 0.0744 - binary_accuracy: 0.9589 - val_loss: 0.2170 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9589\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 126s 20ms/step - loss: 0.1380 - accuracy: 0.0744 - binary_accuracy: 0.9589 - val_loss: 0.2110 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9589\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 19ms/step - loss: 0.1369 - accuracy: 0.0744 - binary_accuracy: 0.9590 - val_loss: 0.2234 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9589\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1381 - accuracy: 0.0744 - binary_accuracy: 0.9590 - val_loss: 0.2167 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9590\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1387 - accuracy: 0.0744 - binary_accuracy: 0.9590 - val_loss: 0.2099 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9590\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 113s 18ms/step - loss: 0.1377 - accuracy: 0.0744 - binary_accuracy: 0.9590 - val_loss: 0.2145 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9590\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 111s 18ms/step - loss: 0.1373 - accuracy: 0.0744 - binary_accuracy: 0.9590 - val_loss: 0.2165 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9590\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1364 - accuracy: 0.0744 - binary_accuracy: 0.9590 - val_loss: 0.2102 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9591\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 18ms/step - loss: 0.1375 - accuracy: 0.0744 - binary_accuracy: 0.9590 - val_loss: 0.2116 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9591\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 120s 19ms/step - loss: 0.1382 - accuracy: 0.0744 - binary_accuracy: 0.9591 - val_loss: 0.2124 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9591\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1387 - accuracy: 0.0744 - binary_accuracy: 0.9591 - val_loss: 0.2197 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9592\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 19ms/step - loss: 0.1378 - accuracy: 0.0744 - binary_accuracy: 0.9591 - val_loss: 0.2136 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9592\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1367 - accuracy: 0.0744 - binary_accuracy: 0.9592 - val_loss: 0.2123 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9592\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1375 - accuracy: 0.0744 - binary_accuracy: 0.9593 - val_loss: 0.2278 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9593\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1369 - accuracy: 0.0744 - binary_accuracy: 0.9593 - val_loss: 0.2209 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9593\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1371 - accuracy: 0.0744 - binary_accuracy: 0.9593 - val_loss: 0.2164 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9593\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 118s 19ms/step - loss: 0.1368 - accuracy: 0.0744 - binary_accuracy: 0.9593 - val_loss: 0.2206 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9594\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 122s 20ms/step - loss: 0.1380 - accuracy: 0.0744 - binary_accuracy: 0.9594 - val_loss: 0.2162 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9594\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 113s 18ms/step - loss: 0.1374 - accuracy: 0.0744 - binary_accuracy: 0.9594 - val_loss: 0.2202 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9594\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 123s 20ms/step - loss: 0.1375 - accuracy: 0.0744 - binary_accuracy: 0.9595 - val_loss: 0.2164 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9594\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 132s 21ms/step - loss: 0.1376 - accuracy: 0.0744 - binary_accuracy: 0.9595 - val_loss: 0.2216 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9595\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1373 - accuracy: 0.0745 - binary_accuracy: 0.9595 - val_loss: 0.2137 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9595\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1387 - accuracy: 0.0744 - binary_accuracy: 0.9595 - val_loss: 0.2229 - val_accuracy: 0.0744 - val_binary_accuracy: 0.9595\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1377 - accuracy: 0.0745 - binary_accuracy: 0.9595 - val_loss: 0.2167 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9596\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 19ms/step - loss: 0.1367 - accuracy: 0.0745 - binary_accuracy: 0.9595 - val_loss: 0.2222 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9596\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 118s 19ms/step - loss: 0.1374 - accuracy: 0.0745 - binary_accuracy: 0.9596 - val_loss: 0.2171 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9596\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 121s 19ms/step - loss: 0.1370 - accuracy: 0.0745 - binary_accuracy: 0.9596 - val_loss: 0.2233 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9597\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 118s 19ms/step - loss: 0.1376 - accuracy: 0.0745 - binary_accuracy: 0.9596 - val_loss: 0.2222 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9597\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1376 - accuracy: 0.0745 - binary_accuracy: 0.9596 - val_loss: 0.2111 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9597\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 120s 19ms/step - loss: 0.1375 - accuracy: 0.0745 - binary_accuracy: 0.9598 - val_loss: 0.2193 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9597\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 122s 20ms/step - loss: 0.1371 - accuracy: 0.0745 - binary_accuracy: 0.9598 - val_loss: 0.2285 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9598\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 131s 21ms/step - loss: 0.1369 - accuracy: 0.0745 - binary_accuracy: 0.9598 - val_loss: 0.2239 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9598\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 130s 21ms/step - loss: 0.1374 - accuracy: 0.0745 - binary_accuracy: 0.9598 - val_loss: 0.2197 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9598\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 129s 21ms/step - loss: 0.1374 - accuracy: 0.0745 - binary_accuracy: 0.9598 - val_loss: 0.2140 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9598\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 116s 19ms/step - loss: 0.1368 - accuracy: 0.0745 - binary_accuracy: 0.9599 - val_loss: 0.2235 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9599\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 117s 19ms/step - loss: 0.1379 - accuracy: 0.0745 - binary_accuracy: 0.9599 - val_loss: 0.2192 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9599\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 122s 20ms/step - loss: 0.1380 - accuracy: 0.0745 - binary_accuracy: 0.9599 - val_loss: 0.2185 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9599\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 119s 19ms/step - loss: 0.1371 - accuracy: 0.0745 - binary_accuracy: 0.9600 - val_loss: 0.2205 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9599\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 120s 19ms/step - loss: 0.1370 - accuracy: 0.0745 - binary_accuracy: 0.9600 - val_loss: 0.2247 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9600\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 115s 19ms/step - loss: 0.1379 - accuracy: 0.0745 - binary_accuracy: 0.9600 - val_loss: 0.2222 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9600\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 112s 18ms/step - loss: 0.1372 - accuracy: 0.0745 - binary_accuracy: 0.9600 - val_loss: 0.2185 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9600\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1375 - accuracy: 0.0745 - binary_accuracy: 0.9600 - val_loss: 0.2252 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9600\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 122s 20ms/step - loss: 0.1380 - accuracy: 0.0745 - binary_accuracy: 0.9600 - val_loss: 0.2107 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9601\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 121s 20ms/step - loss: 0.1370 - accuracy: 0.0745 - binary_accuracy: 0.9600 - val_loss: 0.2254 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9601\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 114s 18ms/step - loss: 0.1381 - accuracy: 0.0745 - binary_accuracy: 0.9601 - val_loss: 0.2096 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9601\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 123s 20ms/step - loss: 0.1378 - accuracy: 0.0745 - binary_accuracy: 0.9601 - val_loss: 0.2247 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9601\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: LearningRateScheduler setting learning rate to 0.0.\n",
      "6201/6201 [==============================] - 3035s 490ms/step - loss: 0.1375 - accuracy: 0.0745 - binary_accuracy: 0.9601 - val_loss: 0.2175 - val_accuracy: 0.0745 - val_binary_accuracy: 0.9601\n"
     ]
    }
   ],
   "source": [
    "predict = model.fit(X_train, y_train, epochs=epochs, callbacks=callbacks, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "accuracy\n",
      "binary_accuracy\n",
      "val_loss\n",
      "val_accuracy\n",
      "val_binary_accuracy\n",
      "lr\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9601454734802246\n",
      "at epoch: 299\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key in predict.history.keys():\n",
    "    print(key)\n",
    "loss_train = predict.history['loss']\n",
    "loss_val = predict.history['val_loss']\n",
    "no_epochs = range(epochs)\n",
    "plt.plot(no_epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(no_epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "loss_train = predict.history['binary_accuracy']\n",
    "loss_val = predict.history['val_binary_accuracy']\n",
    "plt.plot(no_epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(no_epochs, loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "mx = max(loss_val)\n",
    "print(\"accuracy: \", mx)\n",
    "print(\"at epoch:\", loss_val.index(mx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 17:03:23.881731: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999881e-01, 1.44336326e-07],\n",
       "       [9.99999881e-01, 1.15224459e-07],\n",
       "       [9.99998331e-01, 1.61390676e-06],\n",
       "       ...,\n",
       "       [1.02002196e-01, 8.97997797e-01],\n",
       "       [9.48970735e-01, 5.10292351e-02],\n",
       "       [9.14636145e-11, 1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/prateek/Desktop/ML/Major/code_9.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/prateek/Desktop/ML/Major/code_9.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix, accuracy_score\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/prateek/Desktop/ML/Major/code_9.ipynb#ch0000009?line=1'>2</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/prateek/Desktop/ML/Major/code_9.ipynb#ch0000009?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(cm)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/prateek/Desktop/ML/Major/code_9.ipynb#ch0000009?line=3'>4</a>\u001b[0m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=221'>222</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=222'>223</a>\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=223'>224</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=224'>225</a>\u001b[0m     \u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=225'>226</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=226'>227</a>\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=304'>305</a>\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=305'>306</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=306'>307</a>\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=307'>308</a>\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=308'>309</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=89'>90</a>\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=91'>92</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=92'>93</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=93'>94</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=94'>95</a>\u001b[0m             type_true, type_pred\n\u001b[1;32m     <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=95'>96</a>\u001b[0m         )\n\u001b[1;32m     <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=96'>97</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=98'>99</a>\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/prateek/venv/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py?line=99'>100</a>\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key in history.history.keys():\n",
    "    print(key)\n",
    "loss_train = history.history['loss']\n",
    "no_epochs = range(epochs)\n",
    "plt.plot(no_epochs, loss_train, 'g', label='Training loss')\n",
    "# plt.plot(no_epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "loss_train = history.history['binary_accuracy']\n",
    "plt.plot(no_epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=tf.keras.metrics.BinaryAccuracy())\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "# rm -rf logs\n",
    "%load_ext tensorboard\n",
    "log_folder = 'logs'\n",
    "callbacks = [\n",
    "            EarlyStopping(patience = 5),\n",
    "            TensorBoard(log_dir=log_folder)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Epoch 1/100\n",
      "4711/4711 [==============================] - 75s 16ms/step - loss: 0.0252 - binary_accuracy: 0.9924 - val_loss: 0.5137 - val_binary_accuracy: 0.9559\n",
      "Epoch 2/100\n",
      "4711/4711 [==============================] - 76s 16ms/step - loss: 0.0250 - binary_accuracy: 0.9925 - val_loss: 0.5150 - val_binary_accuracy: 0.9560\n",
      "Epoch 3/100\n",
      "4711/4711 [==============================] - 76s 16ms/step - loss: 0.0249 - binary_accuracy: 0.9925 - val_loss: 0.5183 - val_binary_accuracy: 0.9559\n",
      "Epoch 4/100\n",
      "4711/4711 [==============================] - 77s 16ms/step - loss: 0.0247 - binary_accuracy: 0.9926 - val_loss: 0.5204 - val_binary_accuracy: 0.9559\n",
      "Epoch 5/100\n",
      "4711/4711 [==============================] - 76s 16ms/step - loss: 0.0246 - binary_accuracy: 0.9926 - val_loss: 0.5218 - val_binary_accuracy: 0.9558\n",
      "Epoch 6/100\n",
      "4711/4711 [==============================] - 77s 16ms/step - loss: 0.0244 - binary_accuracy: 0.9927 - val_loss: 0.5240 - val_binary_accuracy: 0.9558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14417c940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "# rm -rf logs\n",
    "%load_ext tensorboard\n",
    "log_folder = 'logs'\n",
    "callbacks = [\n",
    "            EarlyStopping(patience = 5),\n",
    "            TensorBoard(log_dir=log_folder)\n",
    "            ]\n",
    "model.fit(training_set, epochs=epochs,validation_data=val_dataset,callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8400f417db452b1fc95af2c99e1a3999f9f2bcaa41ebb17e9c014f684ca7b29d"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
