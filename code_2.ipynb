{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27558 files belonging to 2 classes.\n",
      "Using 22047 files for training.\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 17:05:35.333973: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-16 17:05:35.334082: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27558 files belonging to 2 classes.\n",
      "Using 5511 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "shared_dir = '/Users/prateek/Desktop/ML/Major/data/'\n",
    "input_shape = [32, 32]\n",
    "batch = 32\n",
    "\n",
    "training_set = image_dataset_from_directory(shared_dir,\n",
    "                                            validation_split=0.2,\n",
    "                                            subset=\"training\",\n",
    "                                            batch_size=batch,\n",
    "                                            seed=1,\n",
    "                                            color_mode='rgb',\n",
    "                                            image_size=input_shape)\n",
    "\n",
    "val_dataset = image_dataset_from_directory(shared_dir,\n",
    "                                            validation_split=0.2,\n",
    "                                            subset=\"validation\",\n",
    "                                            batch_size=batch,\n",
    "                                            seed=1,\n",
    "                                            color_mode='rgb',\n",
    "                                            image_size=input_shape)\n",
    "\n",
    "input_shape.append(3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [       tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv_2 (TFOpLamb  (None, 150, 150, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.math.subtract_2 (TFOpLam  (None, 150, 150, 3)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 127, 127, 4)       6916      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 63, 63, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 15876)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 15877     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,793\n",
      "Trainable params: 15,877\n",
      "Non-trainable params: 6,916\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "  1/689 [..............................] - ETA: 6:25 - loss: 0.6634 - binary_accuracy: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 17:08:31.251382: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689/689 [==============================] - ETA: 0s - loss: 0.6715 - binary_accuracy: 0.6241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 17:08:48.316967: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689/689 [==============================] - 21s 30ms/step - loss: 0.6715 - binary_accuracy: 0.6241 - val_loss: 0.6433 - val_binary_accuracy: 0.6110\n",
      "Epoch 2/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.6451 - binary_accuracy: 0.6523 - val_loss: 0.6476 - val_binary_accuracy: 0.6692\n",
      "Epoch 3/50\n",
      "689/689 [==============================] - 20s 28ms/step - loss: 0.6240 - binary_accuracy: 0.6637 - val_loss: 0.6430 - val_binary_accuracy: 0.6483\n",
      "Epoch 4/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.6002 - binary_accuracy: 0.6765 - val_loss: 0.6957 - val_binary_accuracy: 0.6093\n",
      "Epoch 5/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.5942 - binary_accuracy: 0.6837 - val_loss: 0.6313 - val_binary_accuracy: 0.6567\n",
      "Epoch 6/50\n",
      "689/689 [==============================] - 20s 28ms/step - loss: 0.5932 - binary_accuracy: 0.6878 - val_loss: 0.6928 - val_binary_accuracy: 0.6654\n",
      "Epoch 7/50\n",
      "689/689 [==============================] - 20s 29ms/step - loss: 0.5987 - binary_accuracy: 0.6863 - val_loss: 0.6947 - val_binary_accuracy: 0.6607\n",
      "Epoch 8/50\n",
      "689/689 [==============================] - 23s 34ms/step - loss: 0.5676 - binary_accuracy: 0.7061 - val_loss: 0.7064 - val_binary_accuracy: 0.6565\n",
      "Epoch 9/50\n",
      "689/689 [==============================] - 28s 41ms/step - loss: 0.5907 - binary_accuracy: 0.6913 - val_loss: 0.8232 - val_binary_accuracy: 0.6324\n",
      "Epoch 10/50\n",
      "689/689 [==============================] - 36s 53ms/step - loss: 0.5760 - binary_accuracy: 0.7033 - val_loss: 0.9194 - val_binary_accuracy: 0.5995\n",
      "Epoch 11/50\n",
      "689/689 [==============================] - 39s 57ms/step - loss: 0.5624 - binary_accuracy: 0.7083 - val_loss: 0.6693 - val_binary_accuracy: 0.6743\n",
      "Epoch 12/50\n",
      "689/689 [==============================] - 35s 51ms/step - loss: 0.5638 - binary_accuracy: 0.7127 - val_loss: 0.6806 - val_binary_accuracy: 0.6433\n",
      "Epoch 13/50\n",
      "689/689 [==============================] - 31s 44ms/step - loss: 0.5413 - binary_accuracy: 0.7200 - val_loss: 0.6551 - val_binary_accuracy: 0.6500\n",
      "Epoch 14/50\n",
      "689/689 [==============================] - 28s 41ms/step - loss: 0.5439 - binary_accuracy: 0.7213 - val_loss: 0.6886 - val_binary_accuracy: 0.6427\n",
      "Epoch 15/50\n",
      "689/689 [==============================] - 27s 40ms/step - loss: 0.5549 - binary_accuracy: 0.7147 - val_loss: 0.6506 - val_binary_accuracy: 0.6826\n",
      "Epoch 16/50\n",
      "689/689 [==============================] - 27s 39ms/step - loss: 0.5384 - binary_accuracy: 0.7243 - val_loss: 0.6686 - val_binary_accuracy: 0.6712\n",
      "Epoch 17/50\n",
      "689/689 [==============================] - 26s 38ms/step - loss: 0.5405 - binary_accuracy: 0.7265 - val_loss: 0.7112 - val_binary_accuracy: 0.6663\n",
      "Epoch 18/50\n",
      "689/689 [==============================] - 26s 38ms/step - loss: 0.5319 - binary_accuracy: 0.7269 - val_loss: 0.6772 - val_binary_accuracy: 0.6759\n",
      "Epoch 19/50\n",
      "689/689 [==============================] - 26s 38ms/step - loss: 0.5266 - binary_accuracy: 0.7295 - val_loss: 0.6530 - val_binary_accuracy: 0.6703\n",
      "Epoch 20/50\n",
      "689/689 [==============================] - 26s 38ms/step - loss: 0.5406 - binary_accuracy: 0.7252 - val_loss: 0.6621 - val_binary_accuracy: 0.6788\n",
      "Epoch 21/50\n",
      "689/689 [==============================] - 26s 38ms/step - loss: 0.5151 - binary_accuracy: 0.7390 - val_loss: 0.7419 - val_binary_accuracy: 0.6162\n",
      "Epoch 22/50\n",
      "689/689 [==============================] - 26s 38ms/step - loss: 0.5289 - binary_accuracy: 0.7316 - val_loss: 0.7808 - val_binary_accuracy: 0.6507\n",
      "Epoch 23/50\n",
      "689/689 [==============================] - 26s 38ms/step - loss: 0.5130 - binary_accuracy: 0.7386 - val_loss: 0.6989 - val_binary_accuracy: 0.6710\n",
      "Epoch 24/50\n",
      "689/689 [==============================] - 26s 38ms/step - loss: 0.5098 - binary_accuracy: 0.7403 - val_loss: 0.7147 - val_binary_accuracy: 0.6698\n",
      "Epoch 25/50\n",
      "689/689 [==============================] - 948s 1s/step - loss: 0.5145 - binary_accuracy: 0.7399 - val_loss: 0.6732 - val_binary_accuracy: 0.6732\n",
      "Epoch 26/50\n",
      "689/689 [==============================] - 993s 1s/step - loss: 0.5140 - binary_accuracy: 0.7405 - val_loss: 0.6926 - val_binary_accuracy: 0.6578\n",
      "Epoch 27/50\n",
      "689/689 [==============================] - 3885s 6s/step - loss: 0.5099 - binary_accuracy: 0.7446 - val_loss: 0.6854 - val_binary_accuracy: 0.6679\n",
      "Epoch 28/50\n",
      "689/689 [==============================] - 1024s 1s/step - loss: 0.5063 - binary_accuracy: 0.7427 - val_loss: 0.6936 - val_binary_accuracy: 0.6730\n",
      "Epoch 29/50\n",
      "689/689 [==============================] - 20s 29ms/step - loss: 0.5042 - binary_accuracy: 0.7461 - val_loss: 0.7004 - val_binary_accuracy: 0.6707\n",
      "Epoch 30/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4991 - binary_accuracy: 0.7505 - val_loss: 0.6879 - val_binary_accuracy: 0.6627\n",
      "Epoch 31/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4952 - binary_accuracy: 0.7504 - val_loss: 0.7733 - val_binary_accuracy: 0.6596\n",
      "Epoch 32/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4983 - binary_accuracy: 0.7505 - val_loss: 0.7350 - val_binary_accuracy: 0.6705\n",
      "Epoch 33/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.5017 - binary_accuracy: 0.7486 - val_loss: 0.7959 - val_binary_accuracy: 0.6231\n",
      "Epoch 34/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4934 - binary_accuracy: 0.7527 - val_loss: 0.8048 - val_binary_accuracy: 0.6552\n",
      "Epoch 35/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4874 - binary_accuracy: 0.7567 - val_loss: 0.6966 - val_binary_accuracy: 0.6643\n",
      "Epoch 36/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4861 - binary_accuracy: 0.7582 - val_loss: 0.7050 - val_binary_accuracy: 0.6616\n",
      "Epoch 37/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4876 - binary_accuracy: 0.7568 - val_loss: 0.7037 - val_binary_accuracy: 0.6621\n",
      "Epoch 38/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4825 - binary_accuracy: 0.7608 - val_loss: 0.8157 - val_binary_accuracy: 0.6240\n",
      "Epoch 39/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4857 - binary_accuracy: 0.7604 - val_loss: 0.8005 - val_binary_accuracy: 0.6491\n",
      "Epoch 40/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4821 - binary_accuracy: 0.7620 - val_loss: 0.8041 - val_binary_accuracy: 0.6482\n",
      "Epoch 41/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4782 - binary_accuracy: 0.7622 - val_loss: 0.7133 - val_binary_accuracy: 0.6687\n",
      "Epoch 42/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4866 - binary_accuracy: 0.7592 - val_loss: 0.7675 - val_binary_accuracy: 0.6336\n",
      "Epoch 43/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4801 - binary_accuracy: 0.7589 - val_loss: 0.7398 - val_binary_accuracy: 0.6721\n",
      "Epoch 44/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4765 - binary_accuracy: 0.7662 - val_loss: 0.7298 - val_binary_accuracy: 0.6705\n",
      "Epoch 45/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4666 - binary_accuracy: 0.7659 - val_loss: 0.7247 - val_binary_accuracy: 0.6698\n",
      "Epoch 46/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4715 - binary_accuracy: 0.7636 - val_loss: 0.7347 - val_binary_accuracy: 0.6451\n",
      "Epoch 47/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4744 - binary_accuracy: 0.7641 - val_loss: 0.7389 - val_binary_accuracy: 0.6561\n",
      "Epoch 48/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4707 - binary_accuracy: 0.7696 - val_loss: 0.7372 - val_binary_accuracy: 0.6658\n",
      "Epoch 49/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4624 - binary_accuracy: 0.7734 - val_loss: 0.7485 - val_binary_accuracy: 0.6707\n",
      "Epoch 50/50\n",
      "689/689 [==============================] - 19s 28ms/step - loss: 0.4739 - binary_accuracy: 0.7660 - val_loss: 0.7238 - val_binary_accuracy: 0.6647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x111a77670>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras import Model, Input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "base_model = Conv2D(4, kernel_size=(24, 24),activation='relu',input_shape=(150, 150, 3))\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "inputs = Input(shape=(150, 150, 3))\n",
    "x = data_augmentation(inputs) \n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(1)(x)\n",
    "model = Model(inputs, outputs)\n",
    "print(model.summary())\n",
    "model.compile(optimizer='adam', loss=keras.losses.BinaryCrossentropy(from_logits=True),metrics=keras.metrics.BinaryAccuracy())\n",
    "\n",
    "model.fit(training_set, epochs=epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=tf.keras.metrics.BinaryAccuracy())\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "# rm -rf logs\n",
    "%load_ext tensorboard\n",
    "log_folder = 'logs'\n",
    "callbacks = [\n",
    "            EarlyStopping(patience = 5),\n",
    "            TensorBoard(log_dir=log_folder)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 19:20:10.474866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689/689 [==============================] - ETA: 0s - loss: 0.4162 - binary_accuracy: 0.7975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 19:21:15.427303: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689/689 [==============================] - 69s 99ms/step - loss: 0.4162 - binary_accuracy: 0.7975 - val_loss: 0.6957 - val_binary_accuracy: 0.6668\n",
      "Epoch 2/15\n",
      "689/689 [==============================] - 68s 99ms/step - loss: 0.4093 - binary_accuracy: 0.8022 - val_loss: 0.6876 - val_binary_accuracy: 0.6832\n",
      "Epoch 3/15\n",
      "689/689 [==============================] - 68s 98ms/step - loss: 0.4045 - binary_accuracy: 0.8068 - val_loss: 0.6848 - val_binary_accuracy: 0.6794\n",
      "Epoch 4/15\n",
      "689/689 [==============================] - 72s 104ms/step - loss: 0.4031 - binary_accuracy: 0.8057 - val_loss: 0.6871 - val_binary_accuracy: 0.6837\n",
      "Epoch 5/15\n",
      "689/689 [==============================] - 73s 106ms/step - loss: 0.3991 - binary_accuracy: 0.8098 - val_loss: 0.6784 - val_binary_accuracy: 0.6861\n",
      "Epoch 6/15\n",
      "689/689 [==============================] - 73s 107ms/step - loss: 0.3963 - binary_accuracy: 0.8130 - val_loss: 0.6745 - val_binary_accuracy: 0.6839\n",
      "Epoch 7/15\n",
      "689/689 [==============================] - 163s 237ms/step - loss: 0.3943 - binary_accuracy: 0.8149 - val_loss: 0.6698 - val_binary_accuracy: 0.6877\n",
      "Epoch 8/15\n",
      "689/689 [==============================] - 112s 163ms/step - loss: 0.3904 - binary_accuracy: 0.8157 - val_loss: 0.6660 - val_binary_accuracy: 0.6908\n",
      "Epoch 9/15\n",
      "689/689 [==============================] - 102s 148ms/step - loss: 0.3861 - binary_accuracy: 0.8179 - val_loss: 0.6614 - val_binary_accuracy: 0.6990\n",
      "Epoch 10/15\n",
      "689/689 [==============================] - 105s 152ms/step - loss: 0.3836 - binary_accuracy: 0.8216 - val_loss: 0.6673 - val_binary_accuracy: 0.6837\n",
      "Epoch 11/15\n",
      "689/689 [==============================] - 90s 130ms/step - loss: 0.3820 - binary_accuracy: 0.8215 - val_loss: 0.6597 - val_binary_accuracy: 0.7031\n",
      "Epoch 12/15\n",
      "689/689 [==============================] - 73s 106ms/step - loss: 0.3776 - binary_accuracy: 0.8244 - val_loss: 0.6554 - val_binary_accuracy: 0.7021\n",
      "Epoch 13/15\n",
      "689/689 [==============================] - 74s 107ms/step - loss: 0.3767 - binary_accuracy: 0.8254 - val_loss: 0.6567 - val_binary_accuracy: 0.7073\n",
      "Epoch 14/15\n",
      "689/689 [==============================] - 72s 105ms/step - loss: 0.3742 - binary_accuracy: 0.8275 - val_loss: 0.6567 - val_binary_accuracy: 0.6921\n",
      "Epoch 15/15\n",
      "689/689 [==============================] - 71s 104ms/step - loss: 0.3735 - binary_accuracy: 0.8275 - val_loss: 0.6498 - val_binary_accuracy: 0.7035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x295c3e4c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "# rm -rf logs\n",
    "%load_ext tensorboard\n",
    "log_folder = 'logs'\n",
    "callbacks = [\n",
    "            EarlyStopping(patience = 5),\n",
    "            TensorBoard(log_dir=log_folder)\n",
    "            ]\n",
    "model.fit(training_set, epochs=epochs,validation_data=val_dataset,callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8400f417db452b1fc95af2c99e1a3999f9f2bcaa41ebb17e9c014f684ca7b29d"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
