{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_shape: [32, 32, 3]\n",
      "image_data: 26160\n",
      "labels: 26160\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "shared_dir = '/Users/prateek/Desktop/ML/Major/'\n",
    "infected_dir = shared_dir + 'True_parasitized/'\n",
    "uninfected_dir = shared_dir + 'True_uninfected/'\n",
    "input_shape = [32, 32]\n",
    "batch = 32\n",
    "\n",
    "parasitized_data = os.listdir(infected_dir)\n",
    "uninfected_data = os.listdir(uninfected_dir)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for img in parasitized_data:\n",
    "    try:\n",
    "        img_read = plt.imread(infected_dir + img)\n",
    "        img_resize = cv2.resize(img_read, input_shape)\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(1)\n",
    "    except :\n",
    "        None\n",
    "        \n",
    "for img in uninfected_data:\n",
    "    try:\n",
    "        img_read = plt.imread(uninfected_dir + img)\n",
    "        img_resize = cv2.resize(img_read, input_shape)\n",
    "        img_array = img_to_array(img_resize)\n",
    "        data.append(img_array)\n",
    "        labels.append(0)\n",
    "    except:\n",
    "        None\n",
    "\n",
    "input_shape.append(3)\n",
    "image_data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"image_shape:\", input_shape)\n",
    "print(\"image_data:\",len(image_data))\n",
    "print(\"labels:\",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 23544\n",
      "X_test: 2617\n",
      "y_train: 23544\n",
      "y_test: 2617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size = 0.1,random_state = 0)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes = 2)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes = 2)\n",
    "\n",
    "print(\"X_train:\",len(X_train))\n",
    "print(\"X_test:\",len(X_test))\n",
    "print(\"y_train:\",len(y_train))\n",
    "print(\"y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout\n",
    "from keras import Sequential,backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 32, 3]\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 29, 29, 4)         196       \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 14, 14, 4)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 11, 11, 8)         520       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 5, 5, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 5, 5, 8)           0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                12864     \n",
      "                                                                 \n",
      " feature_extractor (Dropout)  (None, 64)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,710\n",
      "Trainable params: 13,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dropout_rate = 0.1\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    input_shape = input_shape.reverse\n",
    "print(input_shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, (4, 4), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(8, kernel_size=(4,4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(dropout_rate, name='feature_extractor'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 22:18:55.625792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663/663 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.5649 - binary_accuracy: 0.5649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 22:19:02.711566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663/663 [==============================] - 9s 11ms/step - loss: 0.6850 - accuracy: 0.5649 - binary_accuracy: 0.5649 - val_loss: 0.6682 - val_accuracy: 0.6059 - val_binary_accuracy: 0.6059\n",
      "Epoch 2/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.6450 - accuracy: 0.6352 - binary_accuracy: 0.6352 - val_loss: 0.6050 - val_accuracy: 0.6913 - val_binary_accuracy: 0.6913\n",
      "Epoch 3/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.6170 - accuracy: 0.6658 - binary_accuracy: 0.6658 - val_loss: 0.5923 - val_accuracy: 0.6968 - val_binary_accuracy: 0.6968\n",
      "Epoch 4/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.5995 - accuracy: 0.6891 - binary_accuracy: 0.6891 - val_loss: 0.5709 - val_accuracy: 0.7079 - val_binary_accuracy: 0.7079\n",
      "Epoch 5/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.5807 - accuracy: 0.7080 - binary_accuracy: 0.7080 - val_loss: 0.5587 - val_accuracy: 0.7304 - val_binary_accuracy: 0.7304\n",
      "Epoch 6/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.5580 - accuracy: 0.7250 - binary_accuracy: 0.7250 - val_loss: 0.5293 - val_accuracy: 0.7546 - val_binary_accuracy: 0.7546\n",
      "Epoch 7/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.5290 - accuracy: 0.7473 - binary_accuracy: 0.7473 - val_loss: 0.4801 - val_accuracy: 0.7805 - val_binary_accuracy: 0.7805\n",
      "Epoch 8/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.4918 - accuracy: 0.7751 - binary_accuracy: 0.7751 - val_loss: 0.4534 - val_accuracy: 0.7826 - val_binary_accuracy: 0.7826\n",
      "Epoch 9/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.4517 - accuracy: 0.7931 - binary_accuracy: 0.7931 - val_loss: 0.4016 - val_accuracy: 0.8433 - val_binary_accuracy: 0.8433\n",
      "Epoch 10/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.3975 - accuracy: 0.8292 - binary_accuracy: 0.8292 - val_loss: 0.3410 - val_accuracy: 0.8561 - val_binary_accuracy: 0.8561\n",
      "Epoch 11/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.3412 - accuracy: 0.8595 - binary_accuracy: 0.8595 - val_loss: 0.3082 - val_accuracy: 0.8586 - val_binary_accuracy: 0.8586\n",
      "Epoch 12/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.3022 - accuracy: 0.8761 - binary_accuracy: 0.8761 - val_loss: 0.2595 - val_accuracy: 0.8938 - val_binary_accuracy: 0.8938\n",
      "Epoch 13/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.2675 - accuracy: 0.8923 - binary_accuracy: 0.8923 - val_loss: 0.2371 - val_accuracy: 0.9028 - val_binary_accuracy: 0.9028\n",
      "Epoch 14/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.2445 - accuracy: 0.9016 - binary_accuracy: 0.9016 - val_loss: 0.2084 - val_accuracy: 0.9172 - val_binary_accuracy: 0.9172\n",
      "Epoch 15/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.2277 - accuracy: 0.9087 - binary_accuracy: 0.9087 - val_loss: 0.2133 - val_accuracy: 0.9062 - val_binary_accuracy: 0.9062\n",
      "Epoch 16/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.2118 - accuracy: 0.9155 - binary_accuracy: 0.9155 - val_loss: 0.2149 - val_accuracy: 0.9053 - val_binary_accuracy: 0.9053\n",
      "Epoch 17/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.1942 - accuracy: 0.9220 - binary_accuracy: 0.9220 - val_loss: 0.1879 - val_accuracy: 0.9278 - val_binary_accuracy: 0.9278\n",
      "Epoch 18/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.1863 - accuracy: 0.9269 - binary_accuracy: 0.9269 - val_loss: 0.1643 - val_accuracy: 0.9316 - val_binary_accuracy: 0.9316\n",
      "Epoch 19/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1747 - accuracy: 0.9319 - binary_accuracy: 0.9319 - val_loss: 0.1700 - val_accuracy: 0.9367 - val_binary_accuracy: 0.9367\n",
      "Epoch 20/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.1661 - accuracy: 0.9352 - binary_accuracy: 0.9352 - val_loss: 0.1708 - val_accuracy: 0.9282 - val_binary_accuracy: 0.9282\n",
      "Epoch 21/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1635 - accuracy: 0.9391 - binary_accuracy: 0.9391 - val_loss: 0.1591 - val_accuracy: 0.9414 - val_binary_accuracy: 0.9414\n",
      "Epoch 22/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1523 - accuracy: 0.9434 - binary_accuracy: 0.9434 - val_loss: 0.1840 - val_accuracy: 0.9435 - val_binary_accuracy: 0.9435\n",
      "Epoch 23/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1483 - accuracy: 0.9463 - binary_accuracy: 0.9463 - val_loss: 0.1338 - val_accuracy: 0.9546 - val_binary_accuracy: 0.9546\n",
      "Epoch 24/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1408 - accuracy: 0.9499 - binary_accuracy: 0.9499 - val_loss: 0.1349 - val_accuracy: 0.9541 - val_binary_accuracy: 0.9541\n",
      "Epoch 25/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1340 - accuracy: 0.9516 - binary_accuracy: 0.9516 - val_loss: 0.1276 - val_accuracy: 0.9541 - val_binary_accuracy: 0.9541\n",
      "Epoch 26/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1301 - accuracy: 0.9538 - binary_accuracy: 0.9538 - val_loss: 0.1352 - val_accuracy: 0.9503 - val_binary_accuracy: 0.9503\n",
      "Epoch 27/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1274 - accuracy: 0.9545 - binary_accuracy: 0.9545 - val_loss: 0.1189 - val_accuracy: 0.9597 - val_binary_accuracy: 0.9597\n",
      "Epoch 28/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1218 - accuracy: 0.9574 - binary_accuracy: 0.9574 - val_loss: 0.1256 - val_accuracy: 0.9512 - val_binary_accuracy: 0.9512\n",
      "Epoch 29/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1174 - accuracy: 0.9596 - binary_accuracy: 0.9596 - val_loss: 0.1095 - val_accuracy: 0.9609 - val_binary_accuracy: 0.9609\n",
      "Epoch 30/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1123 - accuracy: 0.9605 - binary_accuracy: 0.9605 - val_loss: 0.1144 - val_accuracy: 0.9592 - val_binary_accuracy: 0.9592\n",
      "Epoch 31/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1106 - accuracy: 0.9605 - binary_accuracy: 0.9605 - val_loss: 0.1263 - val_accuracy: 0.9605 - val_binary_accuracy: 0.9605\n",
      "Epoch 32/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1085 - accuracy: 0.9626 - binary_accuracy: 0.9626 - val_loss: 0.1136 - val_accuracy: 0.9575 - val_binary_accuracy: 0.9575\n",
      "Epoch 33/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.1018 - accuracy: 0.9640 - binary_accuracy: 0.9640 - val_loss: 0.0983 - val_accuracy: 0.9660 - val_binary_accuracy: 0.9660\n",
      "Epoch 34/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0983 - accuracy: 0.9664 - binary_accuracy: 0.9664 - val_loss: 0.1080 - val_accuracy: 0.9614 - val_binary_accuracy: 0.9614\n",
      "Epoch 35/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0983 - accuracy: 0.9655 - binary_accuracy: 0.9655 - val_loss: 0.1169 - val_accuracy: 0.9571 - val_binary_accuracy: 0.9571\n",
      "Epoch 36/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0950 - accuracy: 0.9679 - binary_accuracy: 0.9679 - val_loss: 0.0959 - val_accuracy: 0.9660 - val_binary_accuracy: 0.9660\n",
      "Epoch 37/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0911 - accuracy: 0.9682 - binary_accuracy: 0.9682 - val_loss: 0.1005 - val_accuracy: 0.9639 - val_binary_accuracy: 0.9639\n",
      "Epoch 38/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0870 - accuracy: 0.9697 - binary_accuracy: 0.9697 - val_loss: 0.0898 - val_accuracy: 0.9673 - val_binary_accuracy: 0.9673\n",
      "Epoch 39/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0869 - accuracy: 0.9704 - binary_accuracy: 0.9704 - val_loss: 0.0845 - val_accuracy: 0.9732 - val_binary_accuracy: 0.9732\n",
      "Epoch 40/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0899 - accuracy: 0.9699 - binary_accuracy: 0.9699 - val_loss: 0.0809 - val_accuracy: 0.9766 - val_binary_accuracy: 0.9766\n",
      "Epoch 41/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0803 - accuracy: 0.9721 - binary_accuracy: 0.9721 - val_loss: 0.0807 - val_accuracy: 0.9724 - val_binary_accuracy: 0.9724\n",
      "Epoch 42/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0781 - accuracy: 0.9723 - binary_accuracy: 0.9723 - val_loss: 0.1011 - val_accuracy: 0.9605 - val_binary_accuracy: 0.9605\n",
      "Epoch 43/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0779 - accuracy: 0.9733 - binary_accuracy: 0.9733 - val_loss: 0.0962 - val_accuracy: 0.9656 - val_binary_accuracy: 0.9656\n",
      "Epoch 44/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0744 - accuracy: 0.9748 - binary_accuracy: 0.9748 - val_loss: 0.0892 - val_accuracy: 0.9741 - val_binary_accuracy: 0.9741\n",
      "Epoch 45/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0739 - accuracy: 0.9739 - binary_accuracy: 0.9739 - val_loss: 0.0797 - val_accuracy: 0.9754 - val_binary_accuracy: 0.9754\n",
      "Epoch 46/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0710 - accuracy: 0.9765 - binary_accuracy: 0.9765 - val_loss: 0.0771 - val_accuracy: 0.9737 - val_binary_accuracy: 0.9737\n",
      "Epoch 47/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0731 - accuracy: 0.9739 - binary_accuracy: 0.9739 - val_loss: 0.0800 - val_accuracy: 0.9758 - val_binary_accuracy: 0.9758\n",
      "Epoch 48/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0707 - accuracy: 0.9759 - binary_accuracy: 0.9759 - val_loss: 0.0692 - val_accuracy: 0.9779 - val_binary_accuracy: 0.9779\n",
      "Epoch 49/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0700 - accuracy: 0.9765 - binary_accuracy: 0.9765 - val_loss: 0.0671 - val_accuracy: 0.9809 - val_binary_accuracy: 0.9809\n",
      "Epoch 50/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0677 - accuracy: 0.9777 - binary_accuracy: 0.9777 - val_loss: 0.0862 - val_accuracy: 0.9711 - val_binary_accuracy: 0.9711\n",
      "Epoch 51/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0698 - accuracy: 0.9770 - binary_accuracy: 0.9770 - val_loss: 0.0670 - val_accuracy: 0.9792 - val_binary_accuracy: 0.9792\n",
      "Epoch 52/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0682 - accuracy: 0.9777 - binary_accuracy: 0.9777 - val_loss: 0.0705 - val_accuracy: 0.9788 - val_binary_accuracy: 0.9788\n",
      "Epoch 53/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0661 - accuracy: 0.9787 - binary_accuracy: 0.9787 - val_loss: 0.0700 - val_accuracy: 0.9809 - val_binary_accuracy: 0.9809\n",
      "Epoch 54/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0664 - accuracy: 0.9773 - binary_accuracy: 0.9773 - val_loss: 0.0701 - val_accuracy: 0.9796 - val_binary_accuracy: 0.9796\n",
      "Epoch 55/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0646 - accuracy: 0.9788 - binary_accuracy: 0.9788 - val_loss: 0.0696 - val_accuracy: 0.9809 - val_binary_accuracy: 0.9809\n",
      "Epoch 56/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0639 - accuracy: 0.9786 - binary_accuracy: 0.9786 - val_loss: 0.0634 - val_accuracy: 0.9813 - val_binary_accuracy: 0.9813\n",
      "Epoch 57/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0635 - accuracy: 0.9786 - binary_accuracy: 0.9786 - val_loss: 0.0680 - val_accuracy: 0.9809 - val_binary_accuracy: 0.9809\n",
      "Epoch 58/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0616 - accuracy: 0.9798 - binary_accuracy: 0.9798 - val_loss: 0.0654 - val_accuracy: 0.9813 - val_binary_accuracy: 0.9813\n",
      "Epoch 59/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0607 - accuracy: 0.9801 - binary_accuracy: 0.9801 - val_loss: 0.0665 - val_accuracy: 0.9796 - val_binary_accuracy: 0.9796\n",
      "Epoch 60/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0612 - accuracy: 0.9798 - binary_accuracy: 0.9798 - val_loss: 0.0612 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 61/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0599 - accuracy: 0.9810 - binary_accuracy: 0.9810 - val_loss: 0.0645 - val_accuracy: 0.9822 - val_binary_accuracy: 0.9822\n",
      "Epoch 62/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0607 - accuracy: 0.9803 - binary_accuracy: 0.9803 - val_loss: 0.0621 - val_accuracy: 0.9822 - val_binary_accuracy: 0.9822\n",
      "Epoch 63/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0580 - accuracy: 0.9807 - binary_accuracy: 0.9807 - val_loss: 0.0612 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 64/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0581 - accuracy: 0.9810 - binary_accuracy: 0.9810 - val_loss: 0.0639 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 65/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0575 - accuracy: 0.9813 - binary_accuracy: 0.9813 - val_loss: 0.0656 - val_accuracy: 0.9800 - val_binary_accuracy: 0.9800\n",
      "Epoch 66/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0580 - accuracy: 0.9817 - binary_accuracy: 0.9817 - val_loss: 0.0624 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 67/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0566 - accuracy: 0.9825 - binary_accuracy: 0.9825 - val_loss: 0.0591 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 68/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0569 - accuracy: 0.9813 - binary_accuracy: 0.9813 - val_loss: 0.0703 - val_accuracy: 0.9783 - val_binary_accuracy: 0.9783\n",
      "Epoch 69/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0560 - accuracy: 0.9815 - binary_accuracy: 0.9815 - val_loss: 0.0595 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 70/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0547 - accuracy: 0.9820 - binary_accuracy: 0.9820 - val_loss: 0.0649 - val_accuracy: 0.9809 - val_binary_accuracy: 0.9809\n",
      "Epoch 71/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0545 - accuracy: 0.9827 - binary_accuracy: 0.9827 - val_loss: 0.0590 - val_accuracy: 0.9822 - val_binary_accuracy: 0.9822\n",
      "Epoch 72/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0534 - accuracy: 0.9832 - binary_accuracy: 0.9832 - val_loss: 0.0602 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 73/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0532 - accuracy: 0.9819 - binary_accuracy: 0.9819 - val_loss: 0.0675 - val_accuracy: 0.9805 - val_binary_accuracy: 0.9805\n",
      "Epoch 74/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0528 - accuracy: 0.9828 - binary_accuracy: 0.9828 - val_loss: 0.0686 - val_accuracy: 0.9809 - val_binary_accuracy: 0.9809\n",
      "Epoch 75/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0522 - accuracy: 0.9828 - binary_accuracy: 0.9828 - val_loss: 0.0714 - val_accuracy: 0.9792 - val_binary_accuracy: 0.9792\n",
      "Epoch 76/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0532 - accuracy: 0.9827 - binary_accuracy: 0.9827 - val_loss: 0.0625 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 77/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0548 - accuracy: 0.9817 - binary_accuracy: 0.9817 - val_loss: 0.0614 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 78/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0527 - accuracy: 0.9824 - binary_accuracy: 0.9824 - val_loss: 0.0574 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 79/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0534 - accuracy: 0.9830 - binary_accuracy: 0.9830 - val_loss: 0.0795 - val_accuracy: 0.9771 - val_binary_accuracy: 0.9771\n",
      "Epoch 80/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0519 - accuracy: 0.9835 - binary_accuracy: 0.9835 - val_loss: 0.0622 - val_accuracy: 0.9822 - val_binary_accuracy: 0.9822\n",
      "Epoch 81/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0509 - accuracy: 0.9836 - binary_accuracy: 0.9836 - val_loss: 0.0680 - val_accuracy: 0.9809 - val_binary_accuracy: 0.9809\n",
      "Epoch 82/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0504 - accuracy: 0.9838 - binary_accuracy: 0.9838 - val_loss: 0.0577 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 83/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0501 - accuracy: 0.9838 - binary_accuracy: 0.9838 - val_loss: 0.0642 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 84/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0490 - accuracy: 0.9850 - binary_accuracy: 0.9850 - val_loss: 0.0588 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 85/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0516 - accuracy: 0.9835 - binary_accuracy: 0.9835 - val_loss: 0.0573 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 86/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0500 - accuracy: 0.9839 - binary_accuracy: 0.9839 - val_loss: 0.0583 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 87/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0493 - accuracy: 0.9844 - binary_accuracy: 0.9844 - val_loss: 0.0554 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 88/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0481 - accuracy: 0.9846 - binary_accuracy: 0.9846 - val_loss: 0.0574 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 89/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0505 - accuracy: 0.9840 - binary_accuracy: 0.9840 - val_loss: 0.0558 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 90/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0484 - accuracy: 0.9842 - binary_accuracy: 0.9842 - val_loss: 0.0635 - val_accuracy: 0.9817 - val_binary_accuracy: 0.9817\n",
      "Epoch 91/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0487 - accuracy: 0.9844 - binary_accuracy: 0.9844 - val_loss: 0.0575 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 92/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0503 - accuracy: 0.9842 - binary_accuracy: 0.9842 - val_loss: 0.0588 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 93/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0467 - accuracy: 0.9856 - binary_accuracy: 0.9856 - val_loss: 0.0567 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 94/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0472 - accuracy: 0.9848 - binary_accuracy: 0.9848 - val_loss: 0.0634 - val_accuracy: 0.9822 - val_binary_accuracy: 0.9822\n",
      "Epoch 95/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0488 - accuracy: 0.9847 - binary_accuracy: 0.9847 - val_loss: 0.0570 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 96/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0483 - accuracy: 0.9843 - binary_accuracy: 0.9843 - val_loss: 0.0555 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 97/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0462 - accuracy: 0.9852 - binary_accuracy: 0.9852 - val_loss: 0.0589 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 98/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0467 - accuracy: 0.9849 - binary_accuracy: 0.9849 - val_loss: 0.0585 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 99/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0477 - accuracy: 0.9855 - binary_accuracy: 0.9855 - val_loss: 0.0573 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 100/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0465 - accuracy: 0.9854 - binary_accuracy: 0.9854 - val_loss: 0.0559 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 101/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0474 - accuracy: 0.9852 - binary_accuracy: 0.9852 - val_loss: 0.0564 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 102/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0470 - accuracy: 0.9854 - binary_accuracy: 0.9854 - val_loss: 0.0575 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 103/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0448 - accuracy: 0.9857 - binary_accuracy: 0.9857 - val_loss: 0.0585 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 104/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0451 - accuracy: 0.9861 - binary_accuracy: 0.9861 - val_loss: 0.0605 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 105/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0444 - accuracy: 0.9871 - binary_accuracy: 0.9871 - val_loss: 0.0642 - val_accuracy: 0.9826 - val_binary_accuracy: 0.9826\n",
      "Epoch 106/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0481 - accuracy: 0.9852 - binary_accuracy: 0.9852 - val_loss: 0.0656 - val_accuracy: 0.9817 - val_binary_accuracy: 0.9817\n",
      "Epoch 107/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0454 - accuracy: 0.9862 - binary_accuracy: 0.9862 - val_loss: 0.0572 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 108/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0430 - accuracy: 0.9867 - binary_accuracy: 0.9867 - val_loss: 0.0685 - val_accuracy: 0.9800 - val_binary_accuracy: 0.9800\n",
      "Epoch 109/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0443 - accuracy: 0.9859 - binary_accuracy: 0.9859 - val_loss: 0.0545 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 110/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0461 - accuracy: 0.9855 - binary_accuracy: 0.9855 - val_loss: 0.0555 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 111/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0451 - accuracy: 0.9853 - binary_accuracy: 0.9853 - val_loss: 0.0566 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 112/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0429 - accuracy: 0.9872 - binary_accuracy: 0.9872 - val_loss: 0.0588 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 113/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0438 - accuracy: 0.9865 - binary_accuracy: 0.9865 - val_loss: 0.0563 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 114/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0453 - accuracy: 0.9860 - binary_accuracy: 0.9860 - val_loss: 0.0569 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 115/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0453 - accuracy: 0.9855 - binary_accuracy: 0.9855 - val_loss: 0.0612 - val_accuracy: 0.9822 - val_binary_accuracy: 0.9822\n",
      "Epoch 116/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0434 - accuracy: 0.9865 - binary_accuracy: 0.9865 - val_loss: 0.0529 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 117/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0408 - accuracy: 0.9876 - binary_accuracy: 0.9876 - val_loss: 0.0665 - val_accuracy: 0.9813 - val_binary_accuracy: 0.9813\n",
      "Epoch 118/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0425 - accuracy: 0.9871 - binary_accuracy: 0.9871 - val_loss: 0.0553 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 119/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0435 - accuracy: 0.9866 - binary_accuracy: 0.9866 - val_loss: 0.0573 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 120/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0423 - accuracy: 0.9870 - binary_accuracy: 0.9870 - val_loss: 0.0567 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 121/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0430 - accuracy: 0.9869 - binary_accuracy: 0.9869 - val_loss: 0.0665 - val_accuracy: 0.9809 - val_binary_accuracy: 0.9809\n",
      "Epoch 122/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0427 - accuracy: 0.9871 - binary_accuracy: 0.9871 - val_loss: 0.0581 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 123/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0420 - accuracy: 0.9871 - binary_accuracy: 0.9871 - val_loss: 0.0554 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 124/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0419 - accuracy: 0.9874 - binary_accuracy: 0.9874 - val_loss: 0.0561 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 125/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0412 - accuracy: 0.9874 - binary_accuracy: 0.9874 - val_loss: 0.0581 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 126/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0427 - accuracy: 0.9865 - binary_accuracy: 0.9865 - val_loss: 0.0632 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 127/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0418 - accuracy: 0.9874 - binary_accuracy: 0.9874 - val_loss: 0.0571 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 128/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0420 - accuracy: 0.9868 - binary_accuracy: 0.9868 - val_loss: 0.0571 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 129/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0418 - accuracy: 0.9870 - binary_accuracy: 0.9870 - val_loss: 0.0540 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 130/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0432 - accuracy: 0.9870 - binary_accuracy: 0.9870 - val_loss: 0.0593 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 131/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0412 - accuracy: 0.9873 - binary_accuracy: 0.9873 - val_loss: 0.0623 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 132/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0440 - accuracy: 0.9856 - binary_accuracy: 0.9856 - val_loss: 0.0546 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 133/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0409 - accuracy: 0.9873 - binary_accuracy: 0.9873 - val_loss: 0.0540 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 134/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0412 - accuracy: 0.9871 - binary_accuracy: 0.9871 - val_loss: 0.0595 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 135/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0410 - accuracy: 0.9879 - binary_accuracy: 0.9879 - val_loss: 0.0585 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 136/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0403 - accuracy: 0.9876 - binary_accuracy: 0.9876 - val_loss: 0.0533 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 137/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0402 - accuracy: 0.9873 - binary_accuracy: 0.9873 - val_loss: 0.0578 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 138/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0395 - accuracy: 0.9882 - binary_accuracy: 0.9882 - val_loss: 0.0529 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 139/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0404 - accuracy: 0.9877 - binary_accuracy: 0.9877 - val_loss: 0.0513 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 140/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0392 - accuracy: 0.9876 - binary_accuracy: 0.9876 - val_loss: 0.0609 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 141/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0399 - accuracy: 0.9876 - binary_accuracy: 0.9876 - val_loss: 0.0552 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 142/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0393 - accuracy: 0.9879 - binary_accuracy: 0.9879 - val_loss: 0.0578 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 143/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0397 - accuracy: 0.9881 - binary_accuracy: 0.9881 - val_loss: 0.0549 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 144/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0391 - accuracy: 0.9880 - binary_accuracy: 0.9880 - val_loss: 0.0538 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 145/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0393 - accuracy: 0.9882 - binary_accuracy: 0.9882 - val_loss: 0.0639 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 146/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0390 - accuracy: 0.9882 - binary_accuracy: 0.9882 - val_loss: 0.0522 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 147/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0390 - accuracy: 0.9877 - binary_accuracy: 0.9877 - val_loss: 0.0534 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 148/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0388 - accuracy: 0.9882 - binary_accuracy: 0.9882 - val_loss: 0.0527 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 149/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0380 - accuracy: 0.9875 - binary_accuracy: 0.9875 - val_loss: 0.0541 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 150/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0379 - accuracy: 0.9885 - binary_accuracy: 0.9885 - val_loss: 0.0514 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 151/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0393 - accuracy: 0.9880 - binary_accuracy: 0.9880 - val_loss: 0.0541 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 152/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0378 - accuracy: 0.9879 - binary_accuracy: 0.9879 - val_loss: 0.0526 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 153/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0396 - accuracy: 0.9877 - binary_accuracy: 0.9877 - val_loss: 0.0548 - val_accuracy: 0.9873 - val_binary_accuracy: 0.9873\n",
      "Epoch 154/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0378 - accuracy: 0.9887 - binary_accuracy: 0.9887 - val_loss: 0.0525 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 155/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0384 - accuracy: 0.9883 - binary_accuracy: 0.9883 - val_loss: 0.0570 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 156/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0370 - accuracy: 0.9886 - binary_accuracy: 0.9886 - val_loss: 0.0573 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 157/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0382 - accuracy: 0.9887 - binary_accuracy: 0.9887 - val_loss: 0.0534 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 158/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0375 - accuracy: 0.9880 - binary_accuracy: 0.9880 - val_loss: 0.0542 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 159/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0385 - accuracy: 0.9882 - binary_accuracy: 0.9882 - val_loss: 0.0556 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 160/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0382 - accuracy: 0.9884 - binary_accuracy: 0.9884 - val_loss: 0.0518 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 161/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0376 - accuracy: 0.9886 - binary_accuracy: 0.9886 - val_loss: 0.0525 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 162/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0381 - accuracy: 0.9886 - binary_accuracy: 0.9886 - val_loss: 0.0548 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 163/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0370 - accuracy: 0.9891 - binary_accuracy: 0.9891 - val_loss: 0.0552 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 164/300\n",
      "663/663 [==============================] - 14s 21ms/step - loss: 0.0365 - accuracy: 0.9881 - binary_accuracy: 0.9881 - val_loss: 0.0623 - val_accuracy: 0.9813 - val_binary_accuracy: 0.9813\n",
      "Epoch 165/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0370 - accuracy: 0.9884 - binary_accuracy: 0.9884 - val_loss: 0.0582 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 166/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0378 - accuracy: 0.9887 - binary_accuracy: 0.9887 - val_loss: 0.0562 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 167/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0370 - accuracy: 0.9883 - binary_accuracy: 0.9883 - val_loss: 0.0540 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 168/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0380 - accuracy: 0.9889 - binary_accuracy: 0.9889 - val_loss: 0.0519 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 169/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0371 - accuracy: 0.9882 - binary_accuracy: 0.9882 - val_loss: 0.0548 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 170/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0361 - accuracy: 0.9896 - binary_accuracy: 0.9896 - val_loss: 0.0529 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 171/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0363 - accuracy: 0.9891 - binary_accuracy: 0.9891 - val_loss: 0.0555 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 172/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0366 - accuracy: 0.9885 - binary_accuracy: 0.9885 - val_loss: 0.0545 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 173/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0368 - accuracy: 0.9884 - binary_accuracy: 0.9884 - val_loss: 0.0538 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 174/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0361 - accuracy: 0.9882 - binary_accuracy: 0.9882 - val_loss: 0.0546 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 175/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0357 - accuracy: 0.9888 - binary_accuracy: 0.9888 - val_loss: 0.0531 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 176/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0367 - accuracy: 0.9888 - binary_accuracy: 0.9888 - val_loss: 0.0520 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 177/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0369 - accuracy: 0.9887 - binary_accuracy: 0.9887 - val_loss: 0.0521 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 178/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0346 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0550 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 179/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0353 - accuracy: 0.9894 - binary_accuracy: 0.9894 - val_loss: 0.0525 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 180/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0353 - accuracy: 0.9895 - binary_accuracy: 0.9895 - val_loss: 0.0542 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 181/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0359 - accuracy: 0.9888 - binary_accuracy: 0.9888 - val_loss: 0.0564 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 182/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0347 - accuracy: 0.9892 - binary_accuracy: 0.9892 - val_loss: 0.0532 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 183/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0352 - accuracy: 0.9887 - binary_accuracy: 0.9887 - val_loss: 0.0558 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 184/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0339 - accuracy: 0.9899 - binary_accuracy: 0.9899 - val_loss: 0.0529 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 185/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0344 - accuracy: 0.9894 - binary_accuracy: 0.9894 - val_loss: 0.0522 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 186/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0349 - accuracy: 0.9893 - binary_accuracy: 0.9893 - val_loss: 0.0542 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 187/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0357 - accuracy: 0.9888 - binary_accuracy: 0.9888 - val_loss: 0.0527 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 188/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0341 - accuracy: 0.9892 - binary_accuracy: 0.9892 - val_loss: 0.0521 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 189/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0341 - accuracy: 0.9891 - binary_accuracy: 0.9891 - val_loss: 0.0531 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 190/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0344 - accuracy: 0.9894 - binary_accuracy: 0.9894 - val_loss: 0.0554 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 191/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0341 - accuracy: 0.9894 - binary_accuracy: 0.9894 - val_loss: 0.0534 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 192/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0338 - accuracy: 0.9898 - binary_accuracy: 0.9898 - val_loss: 0.0517 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 193/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0356 - accuracy: 0.9891 - binary_accuracy: 0.9891 - val_loss: 0.0533 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 194/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0325 - accuracy: 0.9903 - binary_accuracy: 0.9903 - val_loss: 0.0518 - val_accuracy: 0.9877 - val_binary_accuracy: 0.9877\n",
      "Epoch 195/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0347 - accuracy: 0.9886 - binary_accuracy: 0.9886 - val_loss: 0.0523 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 196/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0329 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0538 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 197/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0345 - accuracy: 0.9892 - binary_accuracy: 0.9892 - val_loss: 0.0520 - val_accuracy: 0.9873 - val_binary_accuracy: 0.9873\n",
      "Epoch 198/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0338 - accuracy: 0.9892 - binary_accuracy: 0.9892 - val_loss: 0.0543 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 199/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0348 - accuracy: 0.9895 - binary_accuracy: 0.9895 - val_loss: 0.0512 - val_accuracy: 0.9873 - val_binary_accuracy: 0.9873\n",
      "Epoch 200/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0351 - accuracy: 0.9893 - binary_accuracy: 0.9893 - val_loss: 0.0542 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 201/300\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 0.0332 - accuracy: 0.9894 - binary_accuracy: 0.9894 - val_loss: 0.0550 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 202/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0342 - accuracy: 0.9891 - binary_accuracy: 0.9891 - val_loss: 0.0528 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 203/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0346 - accuracy: 0.9891 - binary_accuracy: 0.9891 - val_loss: 0.0534 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 204/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0322 - accuracy: 0.9901 - binary_accuracy: 0.9901 - val_loss: 0.0570 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 205/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0330 - accuracy: 0.9892 - binary_accuracy: 0.9892 - val_loss: 0.0521 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 206/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0334 - accuracy: 0.9898 - binary_accuracy: 0.9898 - val_loss: 0.0548 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 207/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0328 - accuracy: 0.9901 - binary_accuracy: 0.9901 - val_loss: 0.0510 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 208/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0327 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0504 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 209/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0333 - accuracy: 0.9901 - binary_accuracy: 0.9901 - val_loss: 0.0523 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 210/300\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 0.0329 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0582 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 211/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0329 - accuracy: 0.9901 - binary_accuracy: 0.9901 - val_loss: 0.0509 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 212/300\n",
      "663/663 [==============================] - 10s 15ms/step - loss: 0.0330 - accuracy: 0.9895 - binary_accuracy: 0.9895 - val_loss: 0.0502 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 213/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0324 - accuracy: 0.9899 - binary_accuracy: 0.9899 - val_loss: 0.0546 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 214/300\n",
      "663/663 [==============================] - 10s 15ms/step - loss: 0.0331 - accuracy: 0.9899 - binary_accuracy: 0.9899 - val_loss: 0.0531 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 215/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0329 - accuracy: 0.9898 - binary_accuracy: 0.9898 - val_loss: 0.0512 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 216/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0313 - accuracy: 0.9905 - binary_accuracy: 0.9905 - val_loss: 0.0534 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 217/300\n",
      "663/663 [==============================] - 11s 16ms/step - loss: 0.0333 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0552 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 218/300\n",
      "663/663 [==============================] - 13s 20ms/step - loss: 0.0392 - accuracy: 0.9872 - binary_accuracy: 0.9872 - val_loss: 0.0522 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 219/300\n",
      "663/663 [==============================] - 12s 18ms/step - loss: 0.0326 - accuracy: 0.9898 - binary_accuracy: 0.9898 - val_loss: 0.0509 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 220/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0334 - accuracy: 0.9899 - binary_accuracy: 0.9899 - val_loss: 0.0509 - val_accuracy: 0.9873 - val_binary_accuracy: 0.9873\n",
      "Epoch 221/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0317 - accuracy: 0.9906 - binary_accuracy: 0.9906 - val_loss: 0.0498 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 222/300\n",
      "663/663 [==============================] - 11s 17ms/step - loss: 0.0323 - accuracy: 0.9899 - binary_accuracy: 0.9899 - val_loss: 0.0545 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 223/300\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0331 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0513 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 224/300\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0319 - accuracy: 0.9889 - binary_accuracy: 0.9889 - val_loss: 0.0527 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 225/300\n",
      "663/663 [==============================] - 12s 18ms/step - loss: 0.0308 - accuracy: 0.9901 - binary_accuracy: 0.9901 - val_loss: 0.0513 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 226/300\n",
      "663/663 [==============================] - 11s 17ms/step - loss: 0.0326 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0522 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 227/300\n",
      "663/663 [==============================] - 10s 15ms/step - loss: 0.0330 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0532 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 228/300\n",
      "663/663 [==============================] - 10s 15ms/step - loss: 0.0322 - accuracy: 0.9900 - binary_accuracy: 0.9900 - val_loss: 0.0533 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 229/300\n",
      "663/663 [==============================] - 10s 15ms/step - loss: 0.0319 - accuracy: 0.9905 - binary_accuracy: 0.9905 - val_loss: 0.0515 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 230/300\n",
      "663/663 [==============================] - 10s 15ms/step - loss: 0.0320 - accuracy: 0.9900 - binary_accuracy: 0.9900 - val_loss: 0.0522 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 231/300\n",
      "663/663 [==============================] - 10s 15ms/step - loss: 0.0314 - accuracy: 0.9899 - binary_accuracy: 0.9899 - val_loss: 0.0503 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 232/300\n",
      "663/663 [==============================] - 11s 16ms/step - loss: 0.0323 - accuracy: 0.9898 - binary_accuracy: 0.9898 - val_loss: 0.0526 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 233/300\n",
      "663/663 [==============================] - 11s 16ms/step - loss: 0.0308 - accuracy: 0.9904 - binary_accuracy: 0.9904 - val_loss: 0.0554 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 234/300\n",
      "663/663 [==============================] - 11s 17ms/step - loss: 0.0308 - accuracy: 0.9898 - binary_accuracy: 0.9898 - val_loss: 0.0512 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 235/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0321 - accuracy: 0.9902 - binary_accuracy: 0.9902 - val_loss: 0.0521 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 236/300\n",
      "663/663 [==============================] - 11s 16ms/step - loss: 0.0306 - accuracy: 0.9902 - binary_accuracy: 0.9902 - val_loss: 0.0547 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 237/300\n",
      "663/663 [==============================] - 12s 18ms/step - loss: 0.0320 - accuracy: 0.9894 - binary_accuracy: 0.9894 - val_loss: 0.0521 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 238/300\n",
      "663/663 [==============================] - 12s 19ms/step - loss: 0.0303 - accuracy: 0.9900 - binary_accuracy: 0.9900 - val_loss: 0.0541 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 239/300\n",
      "663/663 [==============================] - 12s 18ms/step - loss: 0.0319 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0529 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 240/300\n",
      "663/663 [==============================] - 11s 17ms/step - loss: 0.0307 - accuracy: 0.9903 - binary_accuracy: 0.9903 - val_loss: 0.0512 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 241/300\n",
      "663/663 [==============================] - 11s 16ms/step - loss: 0.0311 - accuracy: 0.9900 - binary_accuracy: 0.9900 - val_loss: 0.0512 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 242/300\n",
      "663/663 [==============================] - 11s 16ms/step - loss: 0.0310 - accuracy: 0.9906 - binary_accuracy: 0.9906 - val_loss: 0.0527 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 243/300\n",
      "663/663 [==============================] - 11s 16ms/step - loss: 0.0304 - accuracy: 0.9905 - binary_accuracy: 0.9905 - val_loss: 0.0542 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 244/300\n",
      "663/663 [==============================] - 11s 16ms/step - loss: 0.0291 - accuracy: 0.9903 - binary_accuracy: 0.9903 - val_loss: 0.0588 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 245/300\n",
      "663/663 [==============================] - 12s 18ms/step - loss: 0.0315 - accuracy: 0.9904 - binary_accuracy: 0.9904 - val_loss: 0.0546 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 246/300\n",
      "663/663 [==============================] - 11s 17ms/step - loss: 0.0298 - accuracy: 0.9907 - binary_accuracy: 0.9907 - val_loss: 0.0522 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 247/300\n",
      "663/663 [==============================] - 12s 18ms/step - loss: 0.0300 - accuracy: 0.9904 - binary_accuracy: 0.9904 - val_loss: 0.0704 - val_accuracy: 0.9805 - val_binary_accuracy: 0.9805\n",
      "Epoch 248/300\n",
      "663/663 [==============================] - 12s 18ms/step - loss: 0.0309 - accuracy: 0.9908 - binary_accuracy: 0.9908 - val_loss: 0.0511 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 249/300\n",
      "663/663 [==============================] - 12s 17ms/step - loss: 0.0305 - accuracy: 0.9902 - binary_accuracy: 0.9902 - val_loss: 0.0527 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 250/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0323 - accuracy: 0.9901 - binary_accuracy: 0.9901 - val_loss: 0.0582 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 251/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0293 - accuracy: 0.9909 - binary_accuracy: 0.9909 - val_loss: 0.0529 - val_accuracy: 0.9873 - val_binary_accuracy: 0.9873\n",
      "Epoch 252/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0312 - accuracy: 0.9902 - binary_accuracy: 0.9902 - val_loss: 0.0504 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 253/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0304 - accuracy: 0.9900 - binary_accuracy: 0.9900 - val_loss: 0.0515 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 254/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0309 - accuracy: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.0528 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 255/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0295 - accuracy: 0.9907 - binary_accuracy: 0.9907 - val_loss: 0.0507 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 256/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0295 - accuracy: 0.9905 - binary_accuracy: 0.9905 - val_loss: 0.0547 - val_accuracy: 0.9822 - val_binary_accuracy: 0.9822\n",
      "Epoch 257/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0287 - accuracy: 0.9909 - binary_accuracy: 0.9909 - val_loss: 0.0540 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 258/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0288 - accuracy: 0.9907 - binary_accuracy: 0.9907 - val_loss: 0.0497 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 259/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0301 - accuracy: 0.9905 - binary_accuracy: 0.9905 - val_loss: 0.0534 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 260/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0297 - accuracy: 0.9907 - binary_accuracy: 0.9907 - val_loss: 0.0582 - val_accuracy: 0.9847 - val_binary_accuracy: 0.9847\n",
      "Epoch 261/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0295 - accuracy: 0.9899 - binary_accuracy: 0.9899 - val_loss: 0.0534 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 262/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0286 - accuracy: 0.9911 - binary_accuracy: 0.9911 - val_loss: 0.0529 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 263/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0295 - accuracy: 0.9905 - binary_accuracy: 0.9905 - val_loss: 0.0532 - val_accuracy: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 264/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0295 - accuracy: 0.9901 - binary_accuracy: 0.9901 - val_loss: 0.0558 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 265/300\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 0.0272 - accuracy: 0.9910 - binary_accuracy: 0.9910 - val_loss: 0.0544 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 266/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0283 - accuracy: 0.9911 - binary_accuracy: 0.9911 - val_loss: 0.0524 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 267/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0295 - accuracy: 0.9907 - binary_accuracy: 0.9907 - val_loss: 0.0554 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 268/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0280 - accuracy: 0.9913 - binary_accuracy: 0.9913 - val_loss: 0.0514 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 269/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0288 - accuracy: 0.9916 - binary_accuracy: 0.9916 - val_loss: 0.0528 - val_accuracy: 0.9877 - val_binary_accuracy: 0.9877\n",
      "Epoch 270/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0277 - accuracy: 0.9909 - binary_accuracy: 0.9909 - val_loss: 0.0720 - val_accuracy: 0.9805 - val_binary_accuracy: 0.9805\n",
      "Epoch 271/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0290 - accuracy: 0.9910 - binary_accuracy: 0.9910 - val_loss: 0.0514 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 272/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0283 - accuracy: 0.9910 - binary_accuracy: 0.9910 - val_loss: 0.0573 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 273/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0291 - accuracy: 0.9911 - binary_accuracy: 0.9911 - val_loss: 0.0528 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 274/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0274 - accuracy: 0.9910 - binary_accuracy: 0.9910 - val_loss: 0.0585 - val_accuracy: 0.9822 - val_binary_accuracy: 0.9822\n",
      "Epoch 275/300\n",
      "663/663 [==============================] - 10s 15ms/step - loss: 0.0292 - accuracy: 0.9913 - binary_accuracy: 0.9913 - val_loss: 0.0565 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 276/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0281 - accuracy: 0.9913 - binary_accuracy: 0.9913 - val_loss: 0.0581 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 277/300\n",
      "663/663 [==============================] - 10s 14ms/step - loss: 0.0282 - accuracy: 0.9909 - binary_accuracy: 0.9909 - val_loss: 0.0530 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 278/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0282 - accuracy: 0.9914 - binary_accuracy: 0.9914 - val_loss: 0.0630 - val_accuracy: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 279/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0278 - accuracy: 0.9909 - binary_accuracy: 0.9909 - val_loss: 0.0553 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 280/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0275 - accuracy: 0.9913 - binary_accuracy: 0.9913 - val_loss: 0.0536 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 281/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0291 - accuracy: 0.9907 - binary_accuracy: 0.9907 - val_loss: 0.0510 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 282/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0273 - accuracy: 0.9915 - binary_accuracy: 0.9915 - val_loss: 0.0529 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 283/300\n",
      "663/663 [==============================] - 12s 19ms/step - loss: 0.0282 - accuracy: 0.9910 - binary_accuracy: 0.9910 - val_loss: 0.0570 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 284/300\n",
      "663/663 [==============================] - 10s 15ms/step - loss: 0.0275 - accuracy: 0.9911 - binary_accuracy: 0.9911 - val_loss: 0.0574 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 285/300\n",
      "663/663 [==============================] - 10s 14ms/step - loss: 0.0288 - accuracy: 0.9910 - binary_accuracy: 0.9910 - val_loss: 0.0564 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 286/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0291 - accuracy: 0.9906 - binary_accuracy: 0.9906 - val_loss: 0.0566 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 287/300\n",
      "663/663 [==============================] - 10s 16ms/step - loss: 0.0279 - accuracy: 0.9912 - binary_accuracy: 0.9912 - val_loss: 0.0537 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 288/300\n",
      "663/663 [==============================] - 11s 16ms/step - loss: 0.0275 - accuracy: 0.9913 - binary_accuracy: 0.9913 - val_loss: 0.0520 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 289/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0279 - accuracy: 0.9912 - binary_accuracy: 0.9912 - val_loss: 0.0570 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n",
      "Epoch 290/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0288 - accuracy: 0.9902 - binary_accuracy: 0.9902 - val_loss: 0.0514 - val_accuracy: 0.9864 - val_binary_accuracy: 0.9864\n",
      "Epoch 291/300\n",
      "663/663 [==============================] - 10s 14ms/step - loss: 0.0276 - accuracy: 0.9914 - binary_accuracy: 0.9914 - val_loss: 0.0513 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 292/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0278 - accuracy: 0.9914 - binary_accuracy: 0.9914 - val_loss: 0.0545 - val_accuracy: 0.9873 - val_binary_accuracy: 0.9873\n",
      "Epoch 293/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0272 - accuracy: 0.9911 - binary_accuracy: 0.9911 - val_loss: 0.0521 - val_accuracy: 0.9834 - val_binary_accuracy: 0.9834\n",
      "Epoch 294/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0269 - accuracy: 0.9917 - binary_accuracy: 0.9917 - val_loss: 0.0515 - val_accuracy: 0.9843 - val_binary_accuracy: 0.9843\n",
      "Epoch 295/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0290 - accuracy: 0.9905 - binary_accuracy: 0.9905 - val_loss: 0.0592 - val_accuracy: 0.9817 - val_binary_accuracy: 0.9817\n",
      "Epoch 296/300\n",
      "663/663 [==============================] - 8s 13ms/step - loss: 0.0267 - accuracy: 0.9915 - binary_accuracy: 0.9915 - val_loss: 0.0546 - val_accuracy: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 297/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0264 - accuracy: 0.9917 - binary_accuracy: 0.9917 - val_loss: 0.0530 - val_accuracy: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 298/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0270 - accuracy: 0.9915 - binary_accuracy: 0.9915 - val_loss: 0.0526 - val_accuracy: 0.9873 - val_binary_accuracy: 0.9873\n",
      "Epoch 299/300\n",
      "663/663 [==============================] - 9s 14ms/step - loss: 0.0285 - accuracy: 0.9909 - binary_accuracy: 0.9909 - val_loss: 0.0522 - val_accuracy: 0.9851 - val_binary_accuracy: 0.9851\n",
      "Epoch 300/300\n",
      "663/663 [==============================] - 9s 13ms/step - loss: 0.0275 - accuracy: 0.9918 - binary_accuracy: 0.9918 - val_loss: 0.0514 - val_accuracy: 0.9860 - val_binary_accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "epochs = 300\n",
    "\n",
    "accuracy_metrics = ['accuracy', 'binary_accuracy']\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=accuracy_metrics)\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'binary_accuracy', 'val_loss', 'val_accuracy', 'val_binary_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('#f Iterations')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'binary_accuracy', 'val_loss', 'val_accuracy', 'val_binary_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('#f Iterations')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:03:28.501617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2617, 64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "\n",
    "new_model=Model(inputs=model.input,outputs=model.get_layer('feature_extractor').output)\n",
    "train_x=new_model.predict(X_train)\n",
    "X_test=X_test.reshape(X_test.shape[0],32,32,3)\n",
    "test_x=new_model.predict(X_test)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23544\n"
     ]
    }
   ],
   "source": [
    "train_y=[ np.where(r==1)[0][0] for r in y_train ]\n",
    "print(len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm=SVC(kernel='rbf')\n",
    "svm.fit(train_x,train_y)\n",
    "svm.score(train_x,train_y)\n",
    "svm_predict=svm.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1282   12]\n",
      " [  20 1303]]\n",
      "0.9877722583110432\n",
      "0.9877722583110432\n",
      "0.9877722583110432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics._plot.confusion_matrix import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(confusion_matrix( y_test[:,1], svm_predict ))\n",
    "print(accuracy_score(y_test[:, 1], svm_predict))\n",
    "print(precision_score( y_test[:,1], svm_predict, average='micro') )\n",
    "print(recall_score( y_test[:,1], svm_predict, average='micro') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc=KNeighborsClassifier(n_neighbors = 5)\n",
    "knc.fit(train_x,train_y)\n",
    "knc.score(train_x,train_y)\n",
    "knn_predict=knc.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc=KNeighborsClassifier(n_neighbors = 5)\n",
    "knc.fit(train_x,train_y)\n",
    "knc.score(train_x,train_y)\n",
    "knn_predict=knc.predict(test_x)\n",
    "\n",
    "# 2 -> 0.9847153228888039\n",
    "# 3 -> 0.9877722583110432\n",
    "# 4 -> 0.9873901413832633\n",
    "# 5 -> 0.9881543752388231\n",
    "# 6 -> 0.9877722583110432\n",
    "# 7 -> 0.9881543752388231\n",
    "# 8 -> 0.9873901413832633\n",
    "# 9 -> 0.988536492166603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1282   12]\n",
      " [  19 1304]]\n",
      "0.9881543752388231\n",
      "0.9881543752388231\n",
      "0.9881543752388231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics._plot.confusion_matrix import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(confusion_matrix( y_test[:,1], knn_predict ))\n",
    "print(accuracy_score(y_test[:, 1], knn_predict))\n",
    "print( precision_score( y_test[:,1], knn_predict, average='micro') )\n",
    "print( recall_score( y_test[:,1], knn_predict, average='micro') )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8400f417db452b1fc95af2c99e1a3999f9f2bcaa41ebb17e9c014f684ca7b29d"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
